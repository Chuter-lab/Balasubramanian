{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e67ee4a7",
   "metadata": {},
   "source": [
    "\n",
    "#### Author: Madhusudhanan Balasubramanian (MB), Ph.D., The University of Memphis\n",
    "#### V11_Phase3-B copy of ResNet50_Model_V11_Phase3-A\n",
    "Folder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab36144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     3\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        600\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             10.0\n",
      "IMAGES_PER_GPU                 3\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                15\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.7\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               600\n",
      "MEAN_PIXEL                     [123.7, 116.8, 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    3\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        8000\n",
      "POST_NMS_ROIS_TRAINING         1800\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.25, 0.5, 1, 2, 4]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    600\n",
      "STEPS_PER_EPOCH                10\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           600\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        600\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             10.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                15\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.7\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               600\n",
      "MEAN_PIXEL                     [123.7, 116.8, 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    3\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        8000\n",
      "POST_NMS_ROIS_TRAINING         1800\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.25, 0.5, 1, 2, 4]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    600\n",
      "STEPS_PER_EPOCH                10\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           600\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/madhu/Lab/Members/00_madhu/Programs/axon_segmentation/Mask_RCNN/mrcnn/model.py:559: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/madhu/Lab/Members/00_madhu/Programs/axon_segmentation/Mask_RCNN/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/madhu/Lab/Members/00_madhu/Programs/axon_segmentation/Mask_RCNN/mrcnn/model.py:606: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/madhu/Lab/Members/00_madhu/Programs/axon_segmentation/Mask_RCNN/mrcnn/model.py:726: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/madhu/Lab/Members/00_madhu/Programs/axon_segmentation/Mask_RCNN/mrcnn/model.py:728: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/madhu/Lab/Members/00_madhu/Programs/axon_segmentation/Mask_RCNN/mrcnn/model.py:778: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Loading weights from /home/madhu/Lab/Members/00_madhu/Models/axon_annotation/axon_model_v11_e0608.h5\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Dec 10, 2021: based on train_axon_annotation_model.ipynb\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "import imgaug.augmenters as imgAugmenters\n",
    "\n",
    "# Root directory of the project\n",
    "#ROOT_DIR = os.path.abspath(\"../../\")\n",
    "ROOT_DIR = \"./Mask_RCNN\";\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "#MB, Jan 06, 2022: Good configuration references\n",
    "# https://medium.com/@umdfirecoml/training-a-mask-r-cnn-model-using-the-nucleus-data-bcb5fdbc0181\n",
    "# https://medium.com/analytics-vidhya/taming-the-hyper-parameters-of-mask-rcnn-3742cb3f0e1b\n",
    "# https://github.com/matterport/Mask_RCNN/issues/1884\n",
    "#\n",
    "#Model configuration for training\n",
    "#---------------------------------\n",
    "import axon_coco as coco #copied samples/coco/coco.py as axon_coco.py\n",
    "\n",
    "class TrainingConfig(coco.CocoConfig):\n",
    "    #Dec 09, 2021 MB notes: Initially, no other configuration changes needed for training (recall / see that\n",
    "    # configuration changes required for inferences such as setting # GPUs to 1, etc. See axon_coco.py for \n",
    "    # other possible configuration changes\n",
    "    \n",
    "    #General model parameters\n",
    "    BACKBONE = 'resnet50' #default is resnet101\n",
    "    #BACKBONE_STRIDES = [2, 4, 8, 16, 32, 64]\n",
    "    USE_MINI_MASK=True\n",
    "    MEAN_PIXEL = [123.7, 116.8, 103.9]\n",
    "        \n",
    "    #General training parameters\n",
    "    #----------------\n",
    "    IMAGES_PER_GPU = 3 #should be 1 for inference\n",
    "    GPU_COUNT = 1\n",
    "    BATCH_SIZE = IMAGES_PER_GPU * GPU_COUNT #BATCH_SIZE calculated only in config.py's constructor in line 216\n",
    "    #\n",
    "    STEPS_PER_EPOCH = 10 #Jan 07: reduced from 100 to 75; May 10, 2022: steps/epoch = #training images/batch size\n",
    "    VALIDATION_STEPS = 5 #originally 5, previously set at 15\n",
    "    #\n",
    "    GRADIENT_CLIP_NORM = 10.0\n",
    "    LEARNING_MOMENTUM = 0.7\n",
    "    WEIGHT_DECAY=0.0001\n",
    "    LOSS_WEIGHTS = { \"rpn_class_loss\": 1., \"rpn_bbox_loss\": 1., \"mrcnn_class_loss\": 1., \"mrcnn_bbox_loss\": 1., \"mrcnn_mask_loss\": 1. }\n",
    "\n",
    "    #RPN parameters\n",
    "    #---------------\n",
    "    # Length of square anchor side in pixels\n",
    "    #RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)\n",
    "    #RPN_ANCHOR_SCALES = (4, 8, 16, 32, 64) #Incorrectly set this in V11_Phase2 - that's why the model had issues\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128) #Was used in V11 which generated the model e608\n",
    "    # Ratios of anchors at each cell (width/height)\n",
    "    # A value of 1 represents a square anchor, and 0.5 is a wide anchor\n",
    "    #RPN_ANCHOR_RATIOS = [0.5, 1, 2]\n",
    "    RPN_ANCHOR_RATIOS = [0.25, 0.5, 1, 2, 4]\n",
    "    #References for increasing number of detections: https://github.com/matterport/Mask_RCNN/issues/1884#:~:text=What%20seems%20to%20have%20had%20the%20greatest%20impact%20for%20us%20were%20the%20training%20configs%3A\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 600 #default: 256; Number of anchors per image selected to train the RPN\n",
    "    MAX_GT_INSTANCES = 600 #Number of GT instances per image kept to train the network\n",
    "    \n",
    "    #Proposal layer parameters (not trainable layer; just filtering)\n",
    "    #-------------------------\n",
    "    PRE_NMS_LIMIT = 6000 #default: ;Number of anchors with the best RPN score that are retained\n",
    "    RPN_NMS_THRESHOLD = 0.7 #0.7 #default is 0.7; area overlap among candidate anchors before dropping the anchor with the lowest score; higher values increases the number of region proposals\n",
    "    POST_NMS_ROIS_TRAINING = 1800 # >Training; ROIs kept after non-maximum supression in the proposal layer; default is 2000\n",
    "    POST_NMS_ROIS_INFERENCE = 8000 # >Inference; ROIs kept after NMS in the proposal layer based on their RPN score\n",
    "    \n",
    "    #Detection target layer parameters (training only; not a trainable layer; just filtering)\n",
    "    #Receives at most POST_NMS_ROIS_TRAINING number of anchors from the proposal layer\n",
    "    #Anchors whose IoU > 0.5 over ground truth are selected (at most POST_NMS_ROIS_TRAINING)\n",
    "    #---------------------------------\n",
    "    TRAIN_ROIS_PER_IMAGE = 600 #default is 200; no. of ROIs randomly selected out of POST_NMS_ROIS_TRAINING\n",
    "    ROI_POSITIVE_RATIO = 0.33 #default is 0.33; usually set as 1/#classes; i.e. 33% of TRAIN_ROIS_PER_IMAGE should be positive\n",
    "       \n",
    "    #Detection layer parameters (inference only; not trainable, just filtering)\n",
    "    #Receives at most POST_NMS_ROIS_INFERENCE number of anchors from the proposal layer\n",
    "    #MB: https://medium.com/@umdfirecoml/training-a-mask-r-cnn-model-using-the-nucleus-data-bcb5fdbc0181 \n",
    "    #----------------------------\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7#default: 0.7; AOIs with lower confidence than this are discarded\n",
    "    DETECTION_NMS_THRESHOLD = 0.3 #reference: 0.3; AOIs those with higher overlapping areas are discarded based on their RPN score\n",
    "\n",
    "    #Feature Pyramid Network (FPN)\n",
    "    #Has a classifier and mask graph; identifies class and generates mask\n",
    "    #---------------------------------\n",
    "    DETECTION_MAX_INSTANCES = 600 # >Inference; maximum number of instances identified by Mask RCNN\n",
    "    \n",
    "class InferenceConfig(TrainingConfig):\n",
    "    \n",
    "    #General training parameters\n",
    "    #----------------\n",
    "    IMAGES_PER_GPU = 1 #should be 1 for inference\n",
    "    GPU_COUNT = 1\n",
    "    BATCH_SIZE = IMAGES_PER_GPU * GPU_COUNT #BATCH_SIZE calculated only in config.py's constructor in line 216\n",
    "        \n",
    "config = TrainingConfig()\n",
    "config.display()\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "inference_config.display()\n",
    "\n",
    "#Data\n",
    "#-----\n",
    "COCO_DIR = \"./DataFiles/Phase3\"\n",
    "#\n",
    "#Axon training data\n",
    "dataset_train = coco.CocoDataset()\n",
    "dataset_train.load_coco(COCO_DIR, \"Phase3_Training\")\n",
    "dataset_train.prepare() # Must call before using the dataset\n",
    "#\n",
    "#Axon annotation validation data\n",
    "dataset_val = coco.CocoDataset()\n",
    "dataset_val.load_coco(COCO_DIR, \"Phase3_Validation\")\n",
    "dataset_val.prepare() # Must call before using the dataset\n",
    "\n",
    "# Create a model in the \"training\" mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir = coco.DEFAULT_LOGS_DIR)\n",
    "\n",
    "#Create a Mask RCNN model in \"inference\" mode\n",
    "model_inference = modellib.MaskRCNN(mode=\"inference\", config=inference_config, model_dir = coco.DEFAULT_LOGS_DIR)\n",
    "\n",
    "#Initialize the training model with pretrained weights\n",
    "#Note: inference model weights are loaded in the modellib._MeanF1Callback() from the latest trained model\n",
    "init_with = \"specific\"\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    print(\"Loading ImageNet weights\")\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    #MB, Jan 11, 2022\n",
    "    # Download COCO trained weights from Releases if needed -- MB - this needs to be checked if it can download\n",
    "    #if not os.path.exists(coco.COCO_MODEL_PATH):\n",
    "    #    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "    \n",
    "    model_path = os.path.join(coco.ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "    #\n",
    "    print(\"Loading weights from\", model_path)\n",
    "    model.load_weights(model_path, by_name = True,\n",
    "                      exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                              \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"specific\":\n",
    "    #MB Dec 09, 2021: \"specific\" was added to resume training the axon model (not from an initial COCO model)\n",
    "    # So, no need to exclude certain layers as above for \"coco\".  You would choose \"coco\" to start from scratch\n",
    "    #m_dir = \"/home/madhu/Lab/Members/00_madhu/Programs/axon_segmentation/logs/\"\n",
    "    #m_sdir = \"coco20220327T1856\"\n",
    "    #m_name = \"mask_rcnn_coco_0608.h5\"\n",
    "    #\n",
    "    m_dir = \"./\"\n",
    "    m_sdir = \"\"\n",
    "    m_name = \"axon_model_v11_e0608.h5\"\n",
    "    model_path = os.path.join(m_dir, m_sdir, m_name)\n",
    "    #\n",
    "    print(\"Loading weights from\", model_path)\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "elif init_with == \"last\":\n",
    "    #Load the last model training to resume training\n",
    "    model_path = model.find_last()\n",
    "    #\n",
    "    print(\"Loading weights from\", model_path)\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "    \n",
    "# Image Augmentation\n",
    "# Right/Left flip 50% of the time\n",
    "# augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "#max_augs = 4\n",
    "#augmentation = imgAugmenters.SomeOf((0, max_augs),\n",
    "#                                   [\n",
    "#                                       imgAugmenters.Affine(scale={\"x\": (0.5, 1.25), \"y\": (0.5, 1.25)}),\n",
    "#                                       imgAugmenters.Affine(rotate=(-45,45)),\n",
    "#                                       imgAugmenters.Flipud(0.5),\n",
    "#                                       imgAugmenters.Fliplr(0.5)\n",
    "#                                       #imgAugmenters.GaussianBlur(sigma=(0.0, 8.0))\n",
    "#                                   ])\n",
    "\n",
    "#Call back function for tracking multiclass metrics\n",
    "mean_f1_callback = modellib.MeanF1Callback(model, model_inference, dataset_val, \n",
    "                                           calculate_metrics_at_every_X_epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575edc1b",
   "metadata": {},
   "source": [
    "# ARVO 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a6f863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=1e-05. LM=0.7.\n",
      "\n",
      "Checkpoint Path: /home/madhu/Lab/Members/00_madhu/Programs/axon_segmentation/logs/coco20230416T2151/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 272s 27s/step - loss: 1.9135 - rpn_class_loss: 0.1397 - rpn_bbox_loss: 0.3576 - mrcnn_class_loss: 0.5654 - mrcnn_bbox_loss: 0.1991 - mrcnn_mask_loss: 0.6516 - val_loss: 2.2323 - val_rpn_class_loss: 0.2989 - val_rpn_bbox_loss: 0.4085 - val_mrcnn_class_loss: 0.6056 - val_mrcnn_bbox_loss: 0.2029 - val_mrcnn_mask_loss: 0.7164\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/callbacks.py:995: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 15s 1s/step - loss: 1.8953 - rpn_class_loss: 0.1377 - rpn_bbox_loss: 0.3568 - mrcnn_class_loss: 0.5643 - mrcnn_bbox_loss: 0.1995 - mrcnn_mask_loss: 0.6369 - val_loss: 2.1839 - val_rpn_class_loss: 0.2959 - val_rpn_bbox_loss: 0.4078 - val_mrcnn_class_loss: 0.5838 - val_mrcnn_bbox_loss: 0.1987 - val_mrcnn_mask_loss: 0.6977\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 2.1050 - rpn_class_loss: 0.3327 - rpn_bbox_loss: 0.3979 - mrcnn_class_loss: 0.5311 - mrcnn_bbox_loss: 0.1992 - mrcnn_mask_loss: 0.6441 - val_loss: 2.1505 - val_rpn_class_loss: 0.2913 - val_rpn_bbox_loss: 0.4069 - val_mrcnn_class_loss: 0.5688 - val_mrcnn_bbox_loss: 0.1963 - val_mrcnn_mask_loss: 0.6872\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 15s 1s/step - loss: 2.2309 - rpn_class_loss: 0.4571 - rpn_bbox_loss: 0.4248 - mrcnn_class_loss: 0.5050 - mrcnn_bbox_loss: 0.1981 - mrcnn_mask_loss: 0.6458 - val_loss: 2.1444 - val_rpn_class_loss: 0.2845 - val_rpn_bbox_loss: 0.4058 - val_mrcnn_class_loss: 0.5793 - val_mrcnn_bbox_loss: 0.1966 - val_mrcnn_mask_loss: 0.6781\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 2.2075 - rpn_class_loss: 0.4045 - rpn_bbox_loss: 0.4147 - mrcnn_class_loss: 0.5377 - mrcnn_bbox_loss: 0.2038 - mrcnn_mask_loss: 0.6469 - val_loss: 2.1466 - val_rpn_class_loss: 0.2870 - val_rpn_bbox_loss: 0.4093 - val_mrcnn_class_loss: 0.6052 - val_mrcnn_bbox_loss: 0.1947 - val_mrcnn_mask_loss: 0.6503\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 1.9931 - rpn_class_loss: 0.2239 - rpn_bbox_loss: 0.3784 - mrcnn_class_loss: 0.5257 - mrcnn_bbox_loss: 0.2150 - mrcnn_mask_loss: 0.6501 - val_loss: 2.1061 - val_rpn_class_loss: 0.3193 - val_rpn_bbox_loss: 0.4273 - val_mrcnn_class_loss: 0.5651 - val_mrcnn_bbox_loss: 0.2071 - val_mrcnn_mask_loss: 0.5872\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 15s 1s/step - loss: 1.9542 - rpn_class_loss: 0.2209 - rpn_bbox_loss: 0.3776 - mrcnn_class_loss: 0.5050 - mrcnn_bbox_loss: 0.2107 - mrcnn_mask_loss: 0.6400 - val_loss: 2.0571 - val_rpn_class_loss: 0.3161 - val_rpn_bbox_loss: 0.4269 - val_mrcnn_class_loss: 0.5299 - val_mrcnn_bbox_loss: 0.2046 - val_mrcnn_mask_loss: 0.5796\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 15s 1s/step - loss: 1.7087 - rpn_class_loss: 0.1723 - rpn_bbox_loss: 0.3623 - mrcnn_class_loss: 0.4003 - mrcnn_bbox_loss: 0.1907 - mrcnn_mask_loss: 0.5832 - val_loss: 2.1104 - val_rpn_class_loss: 0.3131 - val_rpn_bbox_loss: 0.4264 - val_mrcnn_class_loss: 0.5947 - val_mrcnn_bbox_loss: 0.2049 - val_mrcnn_mask_loss: 0.5713\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.6529 - rpn_class_loss: 0.1587 - rpn_bbox_loss: 0.3577 - mrcnn_class_loss: 0.3807 - mrcnn_bbox_loss: 0.1862 - mrcnn_mask_loss: 0.5697 - val_loss: 2.1050 - val_rpn_class_loss: 0.3103 - val_rpn_bbox_loss: 0.4259 - val_mrcnn_class_loss: 0.5880 - val_mrcnn_bbox_loss: 0.2041 - val_mrcnn_mask_loss: 0.5768\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.8787 - rpn_class_loss: 0.2302 - rpn_bbox_loss: 0.3866 - mrcnn_class_loss: 0.4816 - mrcnn_bbox_loss: 0.1938 - mrcnn_mask_loss: 0.5866 - val_loss: 2.1677 - val_rpn_class_loss: 0.3362 - val_rpn_bbox_loss: 0.4236 - val_mrcnn_class_loss: 0.6279 - val_mrcnn_bbox_loss: 0.2043 - val_mrcnn_mask_loss: 0.5758\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 2.2159 - rpn_class_loss: 0.3354 - rpn_bbox_loss: 0.4303 - mrcnn_class_loss: 0.6459 - mrcnn_bbox_loss: 0.2051 - mrcnn_mask_loss: 0.5992 - val_loss: 2.2401 - val_rpn_class_loss: 0.3740 - val_rpn_bbox_loss: 0.4200 - val_mrcnn_class_loss: 0.6515 - val_mrcnn_bbox_loss: 0.1995 - val_mrcnn_mask_loss: 0.5952\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 2.2179 - rpn_class_loss: 0.3283 - rpn_bbox_loss: 0.4292 - mrcnn_class_loss: 0.6536 - mrcnn_bbox_loss: 0.2042 - mrcnn_mask_loss: 0.6025 - val_loss: 2.2398 - val_rpn_class_loss: 0.3679 - val_rpn_bbox_loss: 0.4192 - val_mrcnn_class_loss: 0.6669 - val_mrcnn_bbox_loss: 0.1941 - val_mrcnn_mask_loss: 0.5917\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.8190 - rpn_class_loss: 0.1934 - rpn_bbox_loss: 0.3585 - mrcnn_class_loss: 0.5032 - mrcnn_bbox_loss: 0.1862 - mrcnn_mask_loss: 0.5777 - val_loss: 2.2222 - val_rpn_class_loss: 0.3638 - val_rpn_bbox_loss: 0.4185 - val_mrcnn_class_loss: 0.6603 - val_mrcnn_bbox_loss: 0.1983 - val_mrcnn_mask_loss: 0.5813\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 71s 7s/step - loss: 1.7985 - rpn_class_loss: 0.1904 - rpn_bbox_loss: 0.3578 - mrcnn_class_loss: 0.4852 - mrcnn_bbox_loss: 0.1843 - mrcnn_mask_loss: 0.5807 - val_loss: 2.1777 - val_rpn_class_loss: 0.3604 - val_rpn_bbox_loss: 0.4179 - val_mrcnn_class_loss: 0.6398 - val_mrcnn_bbox_loss: 0.1934 - val_mrcnn_mask_loss: 0.5662\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 29s 3s/step - loss: 1.7037 - rpn_class_loss: 0.1566 - rpn_bbox_loss: 0.3478 - mrcnn_class_loss: 0.4384 - mrcnn_bbox_loss: 0.1923 - mrcnn_mask_loss: 0.5688 - val_loss: 2.2874 - val_rpn_class_loss: 0.4518 - val_rpn_bbox_loss: 0.4255 - val_mrcnn_class_loss: 0.6025 - val_mrcnn_bbox_loss: 0.2034 - val_mrcnn_mask_loss: 0.6043\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 68s 7s/step - loss: 1.6599 - rpn_class_loss: 0.1340 - rpn_bbox_loss: 0.3408 - mrcnn_class_loss: 0.4356 - mrcnn_bbox_loss: 0.1926 - mrcnn_mask_loss: 0.5568 - val_loss: 2.4186 - val_rpn_class_loss: 0.5111 - val_rpn_bbox_loss: 0.4303 - val_mrcnn_class_loss: 0.6384 - val_mrcnn_bbox_loss: 0.2096 - val_mrcnn_mask_loss: 0.6292\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 86s 9s/step - loss: 1.6891 - rpn_class_loss: 0.1351 - rpn_bbox_loss: 0.3496 - mrcnn_class_loss: 0.4478 - mrcnn_bbox_loss: 0.1959 - mrcnn_mask_loss: 0.5607 - val_loss: 2.3594 - val_rpn_class_loss: 0.5077 - val_rpn_bbox_loss: 0.4297 - val_mrcnn_class_loss: 0.5956 - val_mrcnn_bbox_loss: 0.2064 - val_mrcnn_mask_loss: 0.6201\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 32s 3s/step - loss: 1.8938 - rpn_class_loss: 0.1437 - rpn_bbox_loss: 0.3869 - mrcnn_class_loss: 0.5687 - mrcnn_bbox_loss: 0.2016 - mrcnn_mask_loss: 0.5929 - val_loss: 2.3735 - val_rpn_class_loss: 0.5039 - val_rpn_bbox_loss: 0.4291 - val_mrcnn_class_loss: 0.6058 - val_mrcnn_bbox_loss: 0.2093 - val_mrcnn_mask_loss: 0.6254\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 85s 8s/step - loss: 1.8713 - rpn_class_loss: 0.1419 - rpn_bbox_loss: 0.3862 - mrcnn_class_loss: 0.5520 - mrcnn_bbox_loss: 0.2001 - mrcnn_mask_loss: 0.5911 - val_loss: 2.3657 - val_rpn_class_loss: 0.5001 - val_rpn_bbox_loss: 0.4285 - val_mrcnn_class_loss: 0.6208 - val_mrcnn_bbox_loss: 0.2049 - val_mrcnn_mask_loss: 0.6114\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 121s 12s/step - loss: 1.9529 - rpn_class_loss: 0.2053 - rpn_bbox_loss: 0.3875 - mrcnn_class_loss: 0.5928 - mrcnn_bbox_loss: 0.1923 - mrcnn_mask_loss: 0.5749 - val_loss: 1.9908 - val_rpn_class_loss: 0.3052 - val_rpn_bbox_loss: 0.3816 - val_mrcnn_class_loss: 0.5701 - val_mrcnn_bbox_loss: 0.1878 - val_mrcnn_mask_loss: 0.5460\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 70s 7s/step - loss: 1.9705 - rpn_class_loss: 0.2181 - rpn_bbox_loss: 0.3874 - mrcnn_class_loss: 0.6068 - mrcnn_bbox_loss: 0.1934 - mrcnn_mask_loss: 0.5648 - val_loss: 1.8856 - val_rpn_class_loss: 0.2548 - val_rpn_bbox_loss: 0.3696 - val_mrcnn_class_loss: 0.5628 - val_mrcnn_bbox_loss: 0.1763 - val_mrcnn_mask_loss: 0.5220\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.8041 - rpn_class_loss: 0.1644 - rpn_bbox_loss: 0.3725 - mrcnn_class_loss: 0.5297 - mrcnn_bbox_loss: 0.1888 - mrcnn_mask_loss: 0.5486 - val_loss: 1.8312 - val_rpn_class_loss: 0.2522 - val_rpn_bbox_loss: 0.3691 - val_mrcnn_class_loss: 0.5089 - val_mrcnn_bbox_loss: 0.1778 - val_mrcnn_mask_loss: 0.5231\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.5886 - rpn_class_loss: 0.0876 - rpn_bbox_loss: 0.3505 - mrcnn_class_loss: 0.4482 - mrcnn_bbox_loss: 0.1847 - mrcnn_mask_loss: 0.5176 - val_loss: 1.8870 - val_rpn_class_loss: 0.2506 - val_rpn_bbox_loss: 0.3688 - val_mrcnn_class_loss: 0.5617 - val_mrcnn_bbox_loss: 0.1789 - val_mrcnn_mask_loss: 0.5270\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 130s 13s/step - loss: 1.6811 - rpn_class_loss: 0.1342 - rpn_bbox_loss: 0.3621 - mrcnn_class_loss: 0.4670 - mrcnn_bbox_loss: 0.1820 - mrcnn_mask_loss: 0.5357 - val_loss: 1.8749 - val_rpn_class_loss: 0.2488 - val_rpn_bbox_loss: 0.3684 - val_mrcnn_class_loss: 0.5629 - val_mrcnn_bbox_loss: 0.1759 - val_mrcnn_mask_loss: 0.5189\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 24s 2s/step - loss: 1.7325 - rpn_class_loss: 0.1682 - rpn_bbox_loss: 0.3706 - mrcnn_class_loss: 0.4620 - mrcnn_bbox_loss: 0.1799 - mrcnn_mask_loss: 0.5519 - val_loss: 2.3837 - val_rpn_class_loss: 0.4138 - val_rpn_bbox_loss: 0.4531 - val_mrcnn_class_loss: 0.6893 - val_mrcnn_bbox_loss: 0.2059 - val_mrcnn_mask_loss: 0.6216\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 55s 6s/step - loss: 1.7479 - rpn_class_loss: 0.1896 - rpn_bbox_loss: 0.3759 - mrcnn_class_loss: 0.4608 - mrcnn_bbox_loss: 0.1769 - mrcnn_mask_loss: 0.5446 - val_loss: 2.3728 - val_rpn_class_loss: 0.4101 - val_rpn_bbox_loss: 0.4525 - val_mrcnn_class_loss: 0.6824 - val_mrcnn_bbox_loss: 0.2047 - val_mrcnn_mask_loss: 0.6231\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 136s 14s/step - loss: 1.8062 - rpn_class_loss: 0.1783 - rpn_bbox_loss: 0.3798 - mrcnn_class_loss: 0.5339 - mrcnn_bbox_loss: 0.1854 - mrcnn_mask_loss: 0.5288 - val_loss: 2.2895 - val_rpn_class_loss: 0.4063 - val_rpn_bbox_loss: 0.4518 - val_mrcnn_class_loss: 0.6194 - val_mrcnn_bbox_loss: 0.2011 - val_mrcnn_mask_loss: 0.6109\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 42s 4s/step - loss: 1.8385 - rpn_class_loss: 0.1621 - rpn_bbox_loss: 0.3802 - mrcnn_class_loss: 0.5894 - mrcnn_bbox_loss: 0.1940 - mrcnn_mask_loss: 0.5127 - val_loss: 2.2791 - val_rpn_class_loss: 0.4028 - val_rpn_bbox_loss: 0.4512 - val_mrcnn_class_loss: 0.6316 - val_mrcnn_bbox_loss: 0.2000 - val_mrcnn_mask_loss: 0.5935\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 90s 9s/step - loss: 1.8063 - rpn_class_loss: 0.1510 - rpn_bbox_loss: 0.3747 - mrcnn_class_loss: 0.5772 - mrcnn_bbox_loss: 0.1884 - mrcnn_mask_loss: 0.5149 - val_loss: 2.1611 - val_rpn_class_loss: 0.3454 - val_rpn_bbox_loss: 0.4275 - val_mrcnn_class_loss: 0.6110 - val_mrcnn_bbox_loss: 0.1941 - val_mrcnn_mask_loss: 0.5831\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 41s 4s/step - loss: 1.7137 - rpn_class_loss: 0.1140 - rpn_bbox_loss: 0.3550 - mrcnn_class_loss: 0.5403 - mrcnn_bbox_loss: 0.1834 - mrcnn_mask_loss: 0.5209 - val_loss: 1.6141 - val_rpn_class_loss: 0.1283 - val_rpn_bbox_loss: 0.3343 - val_mrcnn_class_loss: 0.4850 - val_mrcnn_bbox_loss: 0.1827 - val_mrcnn_mask_loss: 0.4838\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 71s 7s/step - loss: 1.7037 - rpn_class_loss: 0.1128 - rpn_bbox_loss: 0.3544 - mrcnn_class_loss: 0.5287 - mrcnn_bbox_loss: 0.1831 - mrcnn_mask_loss: 0.5247 - val_loss: 1.6220 - val_rpn_class_loss: 0.1273 - val_rpn_bbox_loss: 0.3339 - val_mrcnn_class_loss: 0.4995 - val_mrcnn_bbox_loss: 0.1806 - val_mrcnn_mask_loss: 0.4808\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.5490 - rpn_class_loss: 0.0841 - rpn_bbox_loss: 0.3296 - mrcnn_class_loss: 0.4875 - mrcnn_bbox_loss: 0.1745 - mrcnn_mask_loss: 0.4733 - val_loss: 1.6259 - val_rpn_class_loss: 0.1264 - val_rpn_bbox_loss: 0.3335 - val_mrcnn_class_loss: 0.5047 - val_mrcnn_bbox_loss: 0.1826 - val_mrcnn_mask_loss: 0.4786\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 105s 10s/step - loss: 1.5648 - rpn_class_loss: 0.1174 - rpn_bbox_loss: 0.3340 - mrcnn_class_loss: 0.4703 - mrcnn_bbox_loss: 0.1756 - mrcnn_mask_loss: 0.4676 - val_loss: 1.5992 - val_rpn_class_loss: 0.1255 - val_rpn_bbox_loss: 0.3332 - val_mrcnn_class_loss: 0.4855 - val_mrcnn_bbox_loss: 0.1786 - val_mrcnn_mask_loss: 0.4764\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.7289 - rpn_class_loss: 0.2174 - rpn_bbox_loss: 0.3607 - mrcnn_class_loss: 0.5005 - mrcnn_bbox_loss: 0.1750 - mrcnn_mask_loss: 0.4753 - val_loss: 1.7897 - val_rpn_class_loss: 0.2180 - val_rpn_bbox_loss: 0.3702 - val_mrcnn_class_loss: 0.5189 - val_mrcnn_bbox_loss: 0.1829 - val_mrcnn_mask_loss: 0.4998\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 32s 3s/step - loss: 1.6618 - rpn_class_loss: 0.1744 - rpn_bbox_loss: 0.3492 - mrcnn_class_loss: 0.4949 - mrcnn_bbox_loss: 0.1766 - mrcnn_mask_loss: 0.4666 - val_loss: 2.1148 - val_rpn_class_loss: 0.3553 - val_rpn_bbox_loss: 0.4259 - val_mrcnn_class_loss: 0.5955 - val_mrcnn_bbox_loss: 0.1967 - val_mrcnn_mask_loss: 0.5415\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 84s 8s/step - loss: 1.8402 - rpn_class_loss: 0.2705 - rpn_bbox_loss: 0.3757 - mrcnn_class_loss: 0.5380 - mrcnn_bbox_loss: 0.1790 - mrcnn_mask_loss: 0.4770 - val_loss: 2.0757 - val_rpn_class_loss: 0.3513 - val_rpn_bbox_loss: 0.4253 - val_mrcnn_class_loss: 0.5655 - val_mrcnn_bbox_loss: 0.1954 - val_mrcnn_mask_loss: 0.5382\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 15s 1s/step - loss: 1.3580 - rpn_class_loss: 0.0683 - rpn_bbox_loss: 0.3149 - mrcnn_class_loss: 0.3305 - mrcnn_bbox_loss: 0.1859 - mrcnn_mask_loss: 0.4585 - val_loss: 2.1115 - val_rpn_class_loss: 0.3493 - val_rpn_bbox_loss: 0.4249 - val_mrcnn_class_loss: 0.5968 - val_mrcnn_bbox_loss: 0.1959 - val_mrcnn_mask_loss: 0.5447\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 85s 9s/step - loss: 1.5442 - rpn_class_loss: 0.1322 - rpn_bbox_loss: 0.3499 - mrcnn_class_loss: 0.4124 - mrcnn_bbox_loss: 0.1846 - mrcnn_mask_loss: 0.4650 - val_loss: 2.0927 - val_rpn_class_loss: 0.3474 - val_rpn_bbox_loss: 0.4244 - val_mrcnn_class_loss: 0.5902 - val_mrcnn_bbox_loss: 0.1936 - val_mrcnn_mask_loss: 0.5370\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.6256 - rpn_class_loss: 0.1629 - rpn_bbox_loss: 0.3671 - mrcnn_class_loss: 0.4427 - mrcnn_bbox_loss: 0.1850 - mrcnn_mask_loss: 0.4678 - val_loss: 1.8286 - val_rpn_class_loss: 0.2315 - val_rpn_bbox_loss: 0.3725 - val_mrcnn_class_loss: 0.5862 - val_mrcnn_bbox_loss: 0.1729 - val_mrcnn_mask_loss: 0.4655\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 40s 4s/step - loss: 1.6234 - rpn_class_loss: 0.1610 - rpn_bbox_loss: 0.3666 - mrcnn_class_loss: 0.4477 - mrcnn_bbox_loss: 0.1841 - mrcnn_mask_loss: 0.4639 - val_loss: 1.6172 - val_rpn_class_loss: 0.1548 - val_rpn_bbox_loss: 0.3377 - val_mrcnn_class_loss: 0.5430 - val_mrcnn_bbox_loss: 0.1555 - val_mrcnn_mask_loss: 0.4262\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 77s 8s/step - loss: 1.7890 - rpn_class_loss: 0.1953 - rpn_bbox_loss: 0.3909 - mrcnn_class_loss: 0.5359 - mrcnn_bbox_loss: 0.1846 - mrcnn_mask_loss: 0.4824 - val_loss: 1.6191 - val_rpn_class_loss: 0.1531 - val_rpn_bbox_loss: 0.3373 - val_mrcnn_class_loss: 0.5546 - val_mrcnn_bbox_loss: 0.1536 - val_mrcnn_mask_loss: 0.4204\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.6403 - rpn_class_loss: 0.0879 - rpn_bbox_loss: 0.3474 - mrcnn_class_loss: 0.5011 - mrcnn_bbox_loss: 0.1898 - mrcnn_mask_loss: 0.5142 - val_loss: 1.5979 - val_rpn_class_loss: 0.1521 - val_rpn_bbox_loss: 0.3370 - val_mrcnn_class_loss: 0.5420 - val_mrcnn_bbox_loss: 0.1550 - val_mrcnn_mask_loss: 0.4118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "10/10 [==============================] - 15s 1s/step - loss: 1.5602 - rpn_class_loss: 0.0975 - rpn_bbox_loss: 0.3387 - mrcnn_class_loss: 0.4659 - mrcnn_bbox_loss: 0.1793 - mrcnn_mask_loss: 0.4787 - val_loss: 1.6063 - val_rpn_class_loss: 0.1512 - val_rpn_bbox_loss: 0.3367 - val_mrcnn_class_loss: 0.5541 - val_mrcnn_bbox_loss: 0.1553 - val_mrcnn_mask_loss: 0.4090\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 15s 1s/step - loss: 1.5046 - rpn_class_loss: 0.1019 - rpn_bbox_loss: 0.3343 - mrcnn_class_loss: 0.4352 - mrcnn_bbox_loss: 0.1721 - mrcnn_mask_loss: 0.4610 - val_loss: 2.1092 - val_rpn_class_loss: 0.4394 - val_rpn_bbox_loss: 0.4179 - val_mrcnn_class_loss: 0.5934 - val_mrcnn_bbox_loss: 0.1742 - val_mrcnn_mask_loss: 0.4842\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 88s 9s/step - loss: 1.6202 - rpn_class_loss: 0.1548 - rpn_bbox_loss: 0.3576 - mrcnn_class_loss: 0.4654 - mrcnn_bbox_loss: 0.1736 - mrcnn_mask_loss: 0.4688 - val_loss: 2.2135 - val_rpn_class_loss: 0.5089 - val_rpn_bbox_loss: 0.4379 - val_mrcnn_class_loss: 0.5867 - val_mrcnn_bbox_loss: 0.1824 - val_mrcnn_mask_loss: 0.4975\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 24s 2s/step - loss: 1.7093 - rpn_class_loss: 0.2067 - rpn_bbox_loss: 0.3808 - mrcnn_class_loss: 0.4902 - mrcnn_bbox_loss: 0.1726 - mrcnn_mask_loss: 0.4590 - val_loss: 2.2494 - val_rpn_class_loss: 0.5049 - val_rpn_bbox_loss: 0.4375 - val_mrcnn_class_loss: 0.6183 - val_mrcnn_bbox_loss: 0.1853 - val_mrcnn_mask_loss: 0.5034\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 32s 3s/step - loss: 1.6400 - rpn_class_loss: 0.1888 - rpn_bbox_loss: 0.3710 - mrcnn_class_loss: 0.4629 - mrcnn_bbox_loss: 0.1687 - mrcnn_mask_loss: 0.4485 - val_loss: 2.2292 - val_rpn_class_loss: 0.5009 - val_rpn_bbox_loss: 0.4370 - val_mrcnn_class_loss: 0.6129 - val_mrcnn_bbox_loss: 0.1842 - val_mrcnn_mask_loss: 0.4942\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 75s 8s/step - loss: 1.8548 - rpn_class_loss: 0.2715 - rpn_bbox_loss: 0.4102 - mrcnn_class_loss: 0.5296 - mrcnn_bbox_loss: 0.1769 - mrcnn_mask_loss: 0.4666 - val_loss: 2.2420 - val_rpn_class_loss: 0.4958 - val_rpn_bbox_loss: 0.4365 - val_mrcnn_class_loss: 0.6185 - val_mrcnn_bbox_loss: 0.1873 - val_mrcnn_mask_loss: 0.5039\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 1.8392 - rpn_class_loss: 0.2709 - rpn_bbox_loss: 0.4062 - mrcnn_class_loss: 0.5175 - mrcnn_bbox_loss: 0.1777 - mrcnn_mask_loss: 0.4669 - val_loss: 1.9722 - val_rpn_class_loss: 0.3771 - val_rpn_bbox_loss: 0.3917 - val_mrcnn_class_loss: 0.5798 - val_mrcnn_bbox_loss: 0.1724 - val_mrcnn_mask_loss: 0.4513\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 80s 8s/step - loss: 1.8095 - rpn_class_loss: 0.2696 - rpn_bbox_loss: 0.3991 - mrcnn_class_loss: 0.5164 - mrcnn_bbox_loss: 0.1736 - mrcnn_mask_loss: 0.4507 - val_loss: 1.9702 - val_rpn_class_loss: 0.3730 - val_rpn_bbox_loss: 0.3912 - val_mrcnn_class_loss: 0.5949 - val_mrcnn_bbox_loss: 0.1688 - val_mrcnn_mask_loss: 0.4423\n",
      "Fine tune all layers\n",
      "\n",
      "Starting at epoch 50. LR=1e-05. LM=0.7.\n",
      "\n",
      "Checkpoint Path: /home/madhu/Lab/Members/00_madhu/Programs/axon_segmentation/logs/coco20230416T2151/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/75\n",
      "10/10 [==============================] - 476s 48s/step - loss: 1.4976 - rpn_class_loss: 0.0695 - rpn_bbox_loss: 0.3275 - mrcnn_class_loss: 0.5074 - mrcnn_bbox_loss: 0.1683 - mrcnn_mask_loss: 0.4249 - val_loss: 1.7052 - val_rpn_class_loss: 0.1624 - val_rpn_bbox_loss: 0.3764 - val_mrcnn_class_loss: 0.5165 - val_mrcnn_bbox_loss: 0.1687 - val_mrcnn_mask_loss: 0.4811\n",
      "Epoch 52/75\n",
      "10/10 [==============================] - 19s 2s/step - loss: 1.4875 - rpn_class_loss: 0.0655 - rpn_bbox_loss: 0.3258 - mrcnn_class_loss: 0.5064 - mrcnn_bbox_loss: 0.1677 - mrcnn_mask_loss: 0.4220 - val_loss: 1.6869 - val_rpn_class_loss: 0.1580 - val_rpn_bbox_loss: 0.3754 - val_mrcnn_class_loss: 0.5187 - val_mrcnn_bbox_loss: 0.1628 - val_mrcnn_mask_loss: 0.4721\n",
      "Epoch 53/75\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.6404 - rpn_class_loss: 0.1995 - rpn_bbox_loss: 0.3669 - mrcnn_class_loss: 0.4721 - mrcnn_bbox_loss: 0.1664 - mrcnn_mask_loss: 0.4355 - val_loss: 1.6702 - val_rpn_class_loss: 0.1523 - val_rpn_bbox_loss: 0.3741 - val_mrcnn_class_loss: 0.5073 - val_mrcnn_bbox_loss: 0.1644 - val_mrcnn_mask_loss: 0.4721\n",
      "Epoch 54/75\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.7077 - rpn_class_loss: 0.2806 - rpn_bbox_loss: 0.3933 - mrcnn_class_loss: 0.4289 - mrcnn_bbox_loss: 0.1651 - mrcnn_mask_loss: 0.4397 - val_loss: 1.6702 - val_rpn_class_loss: 0.1450 - val_rpn_bbox_loss: 0.3724 - val_mrcnn_class_loss: 0.5362 - val_mrcnn_bbox_loss: 0.1584 - val_mrcnn_mask_loss: 0.4582\n",
      "Epoch 55/75\n",
      "10/10 [==============================] - 109s 11s/step - loss: 1.6647 - rpn_class_loss: 0.2401 - rpn_bbox_loss: 0.3829 - mrcnn_class_loss: 0.4337 - mrcnn_bbox_loss: 0.1679 - mrcnn_mask_loss: 0.4400 - val_loss: 1.6936 - val_rpn_class_loss: 0.1497 - val_rpn_bbox_loss: 0.3780 - val_mrcnn_class_loss: 0.5420 - val_mrcnn_bbox_loss: 0.1667 - val_mrcnn_mask_loss: 0.4572\n",
      "Epoch 56/75\n",
      "10/10 [==============================] - 19s 2s/step - loss: 1.5451 - rpn_class_loss: 0.1212 - rpn_bbox_loss: 0.3481 - mrcnn_class_loss: 0.4547 - mrcnn_bbox_loss: 0.1759 - mrcnn_mask_loss: 0.4452 - val_loss: 1.7041 - val_rpn_class_loss: 0.1909 - val_rpn_bbox_loss: 0.4054 - val_mrcnn_class_loss: 0.4853 - val_mrcnn_bbox_loss: 0.1773 - val_mrcnn_mask_loss: 0.4452\n",
      "Epoch 57/75\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.5094 - rpn_class_loss: 0.1164 - rpn_bbox_loss: 0.3462 - mrcnn_class_loss: 0.4407 - mrcnn_bbox_loss: 0.1713 - mrcnn_mask_loss: 0.4348 - val_loss: 1.7222 - val_rpn_class_loss: 0.1869 - val_rpn_bbox_loss: 0.4044 - val_mrcnn_class_loss: 0.5108 - val_mrcnn_bbox_loss: 0.1748 - val_mrcnn_mask_loss: 0.4452\n",
      "Epoch 58/75\n",
      "10/10 [==============================] - 64s 6s/step - loss: 1.3063 - rpn_class_loss: 0.0772 - rpn_bbox_loss: 0.3276 - mrcnn_class_loss: 0.3540 - mrcnn_bbox_loss: 0.1530 - mrcnn_mask_loss: 0.3946 - val_loss: 1.6910 - val_rpn_class_loss: 0.1836 - val_rpn_bbox_loss: 0.4036 - val_mrcnn_class_loss: 0.4903 - val_mrcnn_bbox_loss: 0.1739 - val_mrcnn_mask_loss: 0.4396\n",
      "Epoch 59/75\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.2383 - rpn_class_loss: 0.0652 - rpn_bbox_loss: 0.3216 - mrcnn_class_loss: 0.3168 - mrcnn_bbox_loss: 0.1495 - mrcnn_mask_loss: 0.3852 - val_loss: 1.7108 - val_rpn_class_loss: 0.1806 - val_rpn_bbox_loss: 0.4029 - val_mrcnn_class_loss: 0.5083 - val_mrcnn_bbox_loss: 0.1750 - val_mrcnn_mask_loss: 0.4439\n",
      "Epoch 60/75\n",
      "10/10 [==============================] - 102s 10s/step - loss: 1.4431 - rpn_class_loss: 0.1050 - rpn_bbox_loss: 0.3500 - mrcnn_class_loss: 0.4279 - mrcnn_bbox_loss: 0.1617 - mrcnn_mask_loss: 0.3986 - val_loss: 1.7138 - val_rpn_class_loss: 0.1943 - val_rpn_bbox_loss: 0.3963 - val_mrcnn_class_loss: 0.5172 - val_mrcnn_bbox_loss: 0.1696 - val_mrcnn_mask_loss: 0.4365\n",
      "Epoch 61/75\n",
      "10/10 [==============================] - 28s 3s/step - loss: 1.7126 - rpn_class_loss: 0.1624 - rpn_bbox_loss: 0.3933 - mrcnn_class_loss: 0.5513 - mrcnn_bbox_loss: 0.1771 - mrcnn_mask_loss: 0.4284 - val_loss: 1.7394 - val_rpn_class_loss: 0.2146 - val_rpn_bbox_loss: 0.3863 - val_mrcnn_class_loss: 0.5540 - val_mrcnn_bbox_loss: 0.1621 - val_mrcnn_mask_loss: 0.4223\n",
      "Epoch 62/75\n",
      "10/10 [==============================] - 27s 3s/step - loss: 1.7202 - rpn_class_loss: 0.1540 - rpn_bbox_loss: 0.3914 - mrcnn_class_loss: 0.5659 - mrcnn_bbox_loss: 0.1777 - mrcnn_mask_loss: 0.4311 - val_loss: 1.6993 - val_rpn_class_loss: 0.2096 - val_rpn_bbox_loss: 0.3853 - val_mrcnn_class_loss: 0.5307 - val_mrcnn_bbox_loss: 0.1615 - val_mrcnn_mask_loss: 0.4122\n",
      "Epoch 63/75\n",
      "10/10 [==============================] - 96s 10s/step - loss: 1.4065 - rpn_class_loss: 0.0906 - rpn_bbox_loss: 0.3284 - mrcnn_class_loss: 0.4145 - mrcnn_bbox_loss: 0.1587 - mrcnn_mask_loss: 0.4143 - val_loss: 1.7208 - val_rpn_class_loss: 0.2081 - val_rpn_bbox_loss: 0.3845 - val_mrcnn_class_loss: 0.5444 - val_mrcnn_bbox_loss: 0.1627 - val_mrcnn_mask_loss: 0.4211\n",
      "Epoch 64/75\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.4082 - rpn_class_loss: 0.0892 - rpn_bbox_loss: 0.3274 - mrcnn_class_loss: 0.4167 - mrcnn_bbox_loss: 0.1608 - mrcnn_mask_loss: 0.4141 - val_loss: 1.7049 - val_rpn_class_loss: 0.2074 - val_rpn_bbox_loss: 0.3838 - val_mrcnn_class_loss: 0.5459 - val_mrcnn_bbox_loss: 0.1592 - val_mrcnn_mask_loss: 0.4086\n",
      "Epoch 65/75\n",
      "10/10 [==============================] - 91s 9s/step - loss: 1.3585 - rpn_class_loss: 0.0725 - rpn_bbox_loss: 0.3167 - mrcnn_class_loss: 0.3976 - mrcnn_bbox_loss: 0.1631 - mrcnn_mask_loss: 0.4087 - val_loss: 1.7988 - val_rpn_class_loss: 0.2561 - val_rpn_bbox_loss: 0.3916 - val_mrcnn_class_loss: 0.5435 - val_mrcnn_bbox_loss: 0.1721 - val_mrcnn_mask_loss: 0.4354\n",
      "Epoch 66/75\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.2899 - rpn_class_loss: 0.0615 - rpn_bbox_loss: 0.3091 - mrcnn_class_loss: 0.3582 - mrcnn_bbox_loss: 0.1593 - mrcnn_mask_loss: 0.4018 - val_loss: 1.8748 - val_rpn_class_loss: 0.2886 - val_rpn_bbox_loss: 0.3966 - val_mrcnn_class_loss: 0.5670 - val_mrcnn_bbox_loss: 0.1782 - val_mrcnn_mask_loss: 0.4444\n",
      "Epoch 67/75\n",
      "10/10 [==============================] - 118s 12s/step - loss: 1.3266 - rpn_class_loss: 0.0615 - rpn_bbox_loss: 0.3174 - mrcnn_class_loss: 0.3871 - mrcnn_bbox_loss: 0.1591 - mrcnn_mask_loss: 0.4016 - val_loss: 1.7952 - val_rpn_class_loss: 0.2880 - val_rpn_bbox_loss: 0.3960 - val_mrcnn_class_loss: 0.5058 - val_mrcnn_bbox_loss: 0.1738 - val_mrcnn_mask_loss: 0.4315\n",
      "Epoch 68/75\n",
      "10/10 [==============================] - 31s 3s/step - loss: 1.5159 - rpn_class_loss: 0.0639 - rpn_bbox_loss: 0.3541 - mrcnn_class_loss: 0.4890 - mrcnn_bbox_loss: 0.1734 - mrcnn_mask_loss: 0.4355 - val_loss: 1.8673 - val_rpn_class_loss: 0.2872 - val_rpn_bbox_loss: 0.3953 - val_mrcnn_class_loss: 0.5497 - val_mrcnn_bbox_loss: 0.1839 - val_mrcnn_mask_loss: 0.4513\n",
      "Epoch 69/75\n",
      "10/10 [==============================] - 18s 2s/step - loss: 1.4913 - rpn_class_loss: 0.0628 - rpn_bbox_loss: 0.3529 - mrcnn_class_loss: 0.4790 - mrcnn_bbox_loss: 0.1717 - mrcnn_mask_loss: 0.4248 - val_loss: 1.8260 - val_rpn_class_loss: 0.2861 - val_rpn_bbox_loss: 0.3945 - val_mrcnn_class_loss: 0.5286 - val_mrcnn_bbox_loss: 0.1769 - val_mrcnn_mask_loss: 0.4399\n",
      "Epoch 70/75\n",
      "10/10 [==============================] - 181s 18s/step - loss: 1.5580 - rpn_class_loss: 0.0959 - rpn_bbox_loss: 0.3591 - mrcnn_class_loss: 0.5277 - mrcnn_bbox_loss: 0.1574 - mrcnn_mask_loss: 0.4180 - val_loss: 1.5950 - val_rpn_class_loss: 0.1699 - val_rpn_bbox_loss: 0.3548 - val_mrcnn_class_loss: 0.5093 - val_mrcnn_bbox_loss: 0.1593 - val_mrcnn_mask_loss: 0.4017\n",
      "Epoch 71/75\n",
      "10/10 [==============================] - 24s 2s/step - loss: 1.5685 - rpn_class_loss: 0.1028 - rpn_bbox_loss: 0.3601 - mrcnn_class_loss: 0.5303 - mrcnn_bbox_loss: 0.1553 - mrcnn_mask_loss: 0.4199 - val_loss: 1.5133 - val_rpn_class_loss: 0.1409 - val_rpn_bbox_loss: 0.3447 - val_mrcnn_class_loss: 0.4860 - val_mrcnn_bbox_loss: 0.1534 - val_mrcnn_mask_loss: 0.3883\n",
      "Epoch 72/75\n",
      "10/10 [==============================] - 50s 5s/step - loss: 1.4703 - rpn_class_loss: 0.0761 - rpn_bbox_loss: 0.3445 - mrcnn_class_loss: 0.4773 - mrcnn_bbox_loss: 0.1603 - mrcnn_mask_loss: 0.4121 - val_loss: 1.5304 - val_rpn_class_loss: 0.1404 - val_rpn_bbox_loss: 0.3443 - val_mrcnn_class_loss: 0.4977 - val_mrcnn_bbox_loss: 0.1570 - val_mrcnn_mask_loss: 0.3910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/75\n",
      "10/10 [==============================] - 26s 3s/step - loss: 1.2862 - rpn_class_loss: 0.0375 - rpn_bbox_loss: 0.3214 - mrcnn_class_loss: 0.3767 - mrcnn_bbox_loss: 0.1638 - mrcnn_mask_loss: 0.3869 - val_loss: 1.4784 - val_rpn_class_loss: 0.1395 - val_rpn_bbox_loss: 0.3440 - val_mrcnn_class_loss: 0.4640 - val_mrcnn_bbox_loss: 0.1513 - val_mrcnn_mask_loss: 0.3795\n",
      "Epoch 74/75\n",
      "10/10 [==============================] - 137s 14s/step - loss: 1.2955 - rpn_class_loss: 0.0429 - rpn_bbox_loss: 0.3229 - mrcnn_class_loss: 0.3810 - mrcnn_bbox_loss: 0.1617 - mrcnn_mask_loss: 0.3870 - val_loss: 1.4866 - val_rpn_class_loss: 0.1386 - val_rpn_bbox_loss: 0.3438 - val_mrcnn_class_loss: 0.4669 - val_mrcnn_bbox_loss: 0.1539 - val_mrcnn_mask_loss: 0.3834\n",
      "Epoch 75/75\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.3865 - rpn_class_loss: 0.0913 - rpn_bbox_loss: 0.3424 - mrcnn_class_loss: 0.3955 - mrcnn_bbox_loss: 0.1491 - mrcnn_mask_loss: 0.4082 - val_loss: 1.8373 - val_rpn_class_loss: 0.2348 - val_rpn_bbox_loss: 0.4200 - val_mrcnn_class_loss: 0.5490 - val_mrcnn_bbox_loss: 0.1732 - val_mrcnn_mask_loss: 0.4603\n"
     ]
    }
   ],
   "source": [
    "#Heads\n",
    "config.LEARNING_MOMENTUM = 0.7\n",
    "config.LEARNING_RATE = 0.00001\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=50, \n",
    "            layers='heads'#,\n",
    "            #custom_callbacks=[mean_f1_callback]\n",
    "           )\n",
    "\n",
    "#Fine-tune all layers\n",
    "print(\"Fine tune all layers\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=75,\n",
    "            layers='all'#,\n",
    "            #custom_callbacks=[mean_f1_callback]\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7647506a",
   "metadata": {},
   "source": [
    "# All Training Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc98593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "config.LEARNING_MOMENTUM = 0.9\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE*10, \n",
    "            epochs=200, \n",
    "            layers='heads',\n",
    "            custom_callbacks=[mean_f1_callback]\n",
    "           )\n",
    "            #augmentation=augmentation) # unfreeze head and just train on last layer\n",
    "\n",
    "#Fine-tune Stage 4+\n",
    "print(\"Fine tune Resnet stage 4 and up\")\n",
    "config.LEARNING_MOMENTUM = 0.9\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE*5,\n",
    "            epochs=300,\n",
    "            layers='4+',\n",
    "            custom_callbacks=[mean_f1_callback]\n",
    "           )\n",
    "            #augmentation=augmentation)\n",
    "    \n",
    "#Fine-tune all layers\n",
    "print(\"Fine tune all layers\")\n",
    "config.LEARNING_MOMENTUM = 0.9\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE*3,\n",
    "            epochs=400,\n",
    "            layers='all',\n",
    "            custom_callbacks=[mean_f1_callback]\n",
    "           )\n",
    "            #augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f02c867",
   "metadata": {},
   "source": [
    "## Train heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785f158f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.0001. LM=0.7.\n",
      "\n",
      "Checkpoint Path: /home/madhu/Lab/Members/00_madhu/Programs/axon_segmentation/logs/coco20230416T1607/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 286s 29s/step - loss: 2.2212 - rpn_class_loss: 0.4036 - rpn_bbox_loss: 0.4155 - mrcnn_class_loss: 0.5410 - mrcnn_bbox_loss: 0.1977 - mrcnn_mask_loss: 0.6634 - val_loss: 2.6292 - val_rpn_class_loss: 0.6186 - val_rpn_bbox_loss: 0.4455 - val_mrcnn_class_loss: 0.6836 - val_mrcnn_bbox_loss: 0.2135 - val_mrcnn_mask_loss: 0.6679\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/callbacks.py:995: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 17s 2s/step - loss: 2.0669 - rpn_class_loss: 0.3445 - rpn_bbox_loss: 0.4050 - mrcnn_class_loss: 0.5238 - mrcnn_bbox_loss: 0.1914 - mrcnn_mask_loss: 0.6021 - val_loss: 2.4580 - val_rpn_class_loss: 0.5386 - val_rpn_bbox_loss: 0.4374 - val_mrcnn_class_loss: 0.6660 - val_mrcnn_bbox_loss: 0.2045 - val_mrcnn_mask_loss: 0.6115\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 1.9431 - rpn_class_loss: 0.2248 - rpn_bbox_loss: 0.4013 - mrcnn_class_loss: 0.5610 - mrcnn_bbox_loss: 0.1892 - mrcnn_mask_loss: 0.5668 - val_loss: 2.3529 - val_rpn_class_loss: 0.4823 - val_rpn_bbox_loss: 0.4308 - val_mrcnn_class_loss: 0.6683 - val_mrcnn_bbox_loss: 0.1987 - val_mrcnn_mask_loss: 0.5728\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.8468 - rpn_class_loss: 0.1513 - rpn_bbox_loss: 0.3978 - mrcnn_class_loss: 0.5749 - mrcnn_bbox_loss: 0.1862 - mrcnn_mask_loss: 0.5367 - val_loss: 2.2620 - val_rpn_class_loss: 0.4448 - val_rpn_bbox_loss: 0.4254 - val_mrcnn_class_loss: 0.6719 - val_mrcnn_bbox_loss: 0.1914 - val_mrcnn_mask_loss: 0.5285\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 16s 2s/step - loss: 1.6950 - rpn_class_loss: 0.1235 - rpn_bbox_loss: 0.3756 - mrcnn_class_loss: 0.5333 - mrcnn_bbox_loss: 0.1747 - mrcnn_mask_loss: 0.4878 - val_loss: 2.0643 - val_rpn_class_loss: 0.3820 - val_rpn_bbox_loss: 0.4231 - val_mrcnn_class_loss: 0.5729 - val_mrcnn_bbox_loss: 0.1864 - val_mrcnn_mask_loss: 0.4998\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 15s 2s/step - loss: 1.4559 - rpn_class_loss: 0.0743 - rpn_bbox_loss: 0.3075 - mrcnn_class_loss: 0.4854 - mrcnn_bbox_loss: 0.1630 - mrcnn_mask_loss: 0.4257 - val_loss: 1.8538 - val_rpn_class_loss: 0.2402 - val_rpn_bbox_loss: 0.4295 - val_mrcnn_class_loss: 0.5361 - val_mrcnn_bbox_loss: 0.1847 - val_mrcnn_mask_loss: 0.4633\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.3799 - rpn_class_loss: 0.0685 - rpn_bbox_loss: 0.3041 - mrcnn_class_loss: 0.4434 - mrcnn_bbox_loss: 0.1593 - mrcnn_mask_loss: 0.4046 - val_loss: 1.8137 - val_rpn_class_loss: 0.2328 - val_rpn_bbox_loss: 0.4275 - val_mrcnn_class_loss: 0.5077 - val_mrcnn_bbox_loss: 0.1833 - val_mrcnn_mask_loss: 0.4624\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.3481 - rpn_class_loss: 0.0755 - rpn_bbox_loss: 0.2974 - mrcnn_class_loss: 0.4590 - mrcnn_bbox_loss: 0.1475 - mrcnn_mask_loss: 0.3687 - val_loss: 1.8266 - val_rpn_class_loss: 0.2259 - val_rpn_bbox_loss: 0.4257 - val_mrcnn_class_loss: 0.5350 - val_mrcnn_bbox_loss: 0.1840 - val_mrcnn_mask_loss: 0.4560\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.3256 - rpn_class_loss: 0.0736 - rpn_bbox_loss: 0.2931 - mrcnn_class_loss: 0.4567 - mrcnn_bbox_loss: 0.1433 - mrcnn_mask_loss: 0.3588 - val_loss: 1.7836 - val_rpn_class_loss: 0.2194 - val_rpn_bbox_loss: 0.4241 - val_mrcnn_class_loss: 0.5139 - val_mrcnn_bbox_loss: 0.1779 - val_mrcnn_mask_loss: 0.4484\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 15s 1s/step - loss: 1.3516 - rpn_class_loss: 0.0749 - rpn_bbox_loss: 0.3256 - mrcnn_class_loss: 0.4310 - mrcnn_bbox_loss: 0.1491 - mrcnn_mask_loss: 0.3711 - val_loss: 1.6366 - val_rpn_class_loss: 0.1655 - val_rpn_bbox_loss: 0.3875 - val_mrcnn_class_loss: 0.4994 - val_mrcnn_bbox_loss: 0.1670 - val_mrcnn_mask_loss: 0.4171\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 16s 2s/step - loss: 1.4227 - rpn_class_loss: 0.0781 - rpn_bbox_loss: 0.3763 - mrcnn_class_loss: 0.4073 - mrcnn_bbox_loss: 0.1586 - mrcnn_mask_loss: 0.4024 - val_loss: 1.4272 - val_rpn_class_loss: 0.0894 - val_rpn_bbox_loss: 0.3330 - val_mrcnn_class_loss: 0.4769 - val_mrcnn_bbox_loss: 0.1584 - val_mrcnn_mask_loss: 0.3695\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 18s 2s/step - loss: 1.3840 - rpn_class_loss: 0.0722 - rpn_bbox_loss: 0.3732 - mrcnn_class_loss: 0.3950 - mrcnn_bbox_loss: 0.1548 - mrcnn_mask_loss: 0.3888 - val_loss: 1.4093 - val_rpn_class_loss: 0.0850 - val_rpn_bbox_loss: 0.3313 - val_mrcnn_class_loss: 0.4827 - val_mrcnn_bbox_loss: 0.1524 - val_mrcnn_mask_loss: 0.3579\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 148s 15s/step - loss: 1.7062 - rpn_class_loss: 0.1975 - rpn_bbox_loss: 0.3944 - mrcnn_class_loss: 0.5157 - mrcnn_bbox_loss: 0.1774 - mrcnn_mask_loss: 0.4213 - val_loss: 1.3612 - val_rpn_class_loss: 0.0765 - val_rpn_bbox_loss: 0.3291 - val_mrcnn_class_loss: 0.4715 - val_mrcnn_bbox_loss: 0.1471 - val_mrcnn_mask_loss: 0.3370\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 32s 3s/step - loss: 1.6605 - rpn_class_loss: 0.1758 - rpn_bbox_loss: 0.3907 - mrcnn_class_loss: 0.5124 - mrcnn_bbox_loss: 0.1728 - mrcnn_mask_loss: 0.4088 - val_loss: 1.3030 - val_rpn_class_loss: 0.0686 - val_rpn_bbox_loss: 0.3272 - val_mrcnn_class_loss: 0.4142 - val_mrcnn_bbox_loss: 0.1512 - val_mrcnn_mask_loss: 0.3418\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 84s 8s/step - loss: 1.3993 - rpn_class_loss: 0.1050 - rpn_bbox_loss: 0.3482 - mrcnn_class_loss: 0.4249 - mrcnn_bbox_loss: 0.1554 - mrcnn_mask_loss: 0.3658 - val_loss: 1.5412 - val_rpn_class_loss: 0.1165 - val_rpn_bbox_loss: 0.3667 - val_mrcnn_class_loss: 0.5239 - val_mrcnn_bbox_loss: 0.1515 - val_mrcnn_mask_loss: 0.3826\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 32s 3s/step - loss: 1.2509 - rpn_class_loss: 0.0635 - rpn_bbox_loss: 0.3196 - mrcnn_class_loss: 0.3760 - mrcnn_bbox_loss: 0.1484 - mrcnn_mask_loss: 0.3434 - val_loss: 1.6357 - val_rpn_class_loss: 0.1478 - val_rpn_bbox_loss: 0.3928 - val_mrcnn_class_loss: 0.5314 - val_mrcnn_bbox_loss: 0.1573 - val_mrcnn_mask_loss: 0.4065\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 84s 8s/step - loss: 1.2670 - rpn_class_loss: 0.0563 - rpn_bbox_loss: 0.3178 - mrcnn_class_loss: 0.3942 - mrcnn_bbox_loss: 0.1494 - mrcnn_mask_loss: 0.3493 - val_loss: 1.6363 - val_rpn_class_loss: 0.1448 - val_rpn_bbox_loss: 0.3917 - val_mrcnn_class_loss: 0.5400 - val_mrcnn_bbox_loss: 0.1563 - val_mrcnn_mask_loss: 0.4035\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 32s 3s/step - loss: 1.3170 - rpn_class_loss: 0.0401 - rpn_bbox_loss: 0.3184 - mrcnn_class_loss: 0.4309 - mrcnn_bbox_loss: 0.1585 - mrcnn_mask_loss: 0.3691 - val_loss: 1.6035 - val_rpn_class_loss: 0.1449 - val_rpn_bbox_loss: 0.3910 - val_mrcnn_class_loss: 0.5205 - val_mrcnn_bbox_loss: 0.1501 - val_mrcnn_mask_loss: 0.3969\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 18s 2s/step - loss: 1.2978 - rpn_class_loss: 0.0395 - rpn_bbox_loss: 0.3169 - mrcnn_class_loss: 0.4188 - mrcnn_bbox_loss: 0.1562 - mrcnn_mask_loss: 0.3664 - val_loss: 1.5670 - val_rpn_class_loss: 0.1455 - val_rpn_bbox_loss: 0.3905 - val_mrcnn_class_loss: 0.4908 - val_mrcnn_bbox_loss: 0.1478 - val_mrcnn_mask_loss: 0.3924\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 65s 7s/step - loss: 1.2604 - rpn_class_loss: 0.0293 - rpn_bbox_loss: 0.3020 - mrcnn_class_loss: 0.4295 - mrcnn_bbox_loss: 0.1555 - mrcnn_mask_loss: 0.3441 - val_loss: 1.3821 - val_rpn_class_loss: 0.0934 - val_rpn_bbox_loss: 0.3316 - val_mrcnn_class_loss: 0.4838 - val_mrcnn_bbox_loss: 0.1382 - val_mrcnn_mask_loss: 0.3351\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 18s 2s/step - loss: 1.2388 - rpn_class_loss: 0.0262 - rpn_bbox_loss: 0.2967 - mrcnn_class_loss: 0.4258 - mrcnn_bbox_loss: 0.1552 - mrcnn_mask_loss: 0.3349 - val_loss: 1.3102 - val_rpn_class_loss: 0.0798 - val_rpn_bbox_loss: 0.3167 - val_mrcnn_class_loss: 0.4607 - val_mrcnn_bbox_loss: 0.1338 - val_mrcnn_mask_loss: 0.3192\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.1983 - rpn_class_loss: 0.0310 - rpn_bbox_loss: 0.3116 - mrcnn_class_loss: 0.3680 - mrcnn_bbox_loss: 0.1525 - mrcnn_mask_loss: 0.3352 - val_loss: 1.3142 - val_rpn_class_loss: 0.0791 - val_rpn_bbox_loss: 0.3165 - val_mrcnn_class_loss: 0.4609 - val_mrcnn_bbox_loss: 0.1349 - val_mrcnn_mask_loss: 0.3228\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 28s 3s/step - loss: 1.1650 - rpn_class_loss: 0.0384 - rpn_bbox_loss: 0.3350 - mrcnn_class_loss: 0.3008 - mrcnn_bbox_loss: 0.1507 - mrcnn_mask_loss: 0.3401 - val_loss: 1.2718 - val_rpn_class_loss: 0.0782 - val_rpn_bbox_loss: 0.3163 - val_mrcnn_class_loss: 0.4292 - val_mrcnn_bbox_loss: 0.1300 - val_mrcnn_mask_loss: 0.3182\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 1.1472 - rpn_class_loss: 0.0373 - rpn_bbox_loss: 0.3328 - mrcnn_class_loss: 0.2963 - mrcnn_bbox_loss: 0.1491 - mrcnn_mask_loss: 0.3317 - val_loss: 1.2976 - val_rpn_class_loss: 0.0774 - val_rpn_bbox_loss: 0.3161 - val_mrcnn_class_loss: 0.4544 - val_mrcnn_bbox_loss: 0.1308 - val_mrcnn_mask_loss: 0.3190\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.0318 - rpn_class_loss: 0.0287 - rpn_bbox_loss: 0.2785 - mrcnn_class_loss: 0.2771 - mrcnn_bbox_loss: 0.1329 - mrcnn_mask_loss: 0.3146 - val_loss: 1.3900 - val_rpn_class_loss: 0.1146 - val_rpn_bbox_loss: 0.3481 - val_mrcnn_class_loss: 0.4410 - val_mrcnn_bbox_loss: 0.1477 - val_mrcnn_mask_loss: 0.3386\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 18s 2s/step - loss: 1.0193 - rpn_class_loss: 0.0282 - rpn_bbox_loss: 0.2767 - mrcnn_class_loss: 0.2663 - mrcnn_bbox_loss: 0.1340 - mrcnn_mask_loss: 0.3141 - val_loss: 1.3500 - val_rpn_class_loss: 0.1145 - val_rpn_bbox_loss: 0.3481 - val_mrcnn_class_loss: 0.4114 - val_mrcnn_bbox_loss: 0.1450 - val_mrcnn_mask_loss: 0.3310\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 133s 13s/step - loss: 1.1591 - rpn_class_loss: 0.0445 - rpn_bbox_loss: 0.3030 - mrcnn_class_loss: 0.3613 - mrcnn_bbox_loss: 0.1283 - mrcnn_mask_loss: 0.3219 - val_loss: 1.3434 - val_rpn_class_loss: 0.1141 - val_rpn_bbox_loss: 0.3480 - val_mrcnn_class_loss: 0.4027 - val_mrcnn_bbox_loss: 0.1463 - val_mrcnn_mask_loss: 0.3322\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 1.2084 - rpn_class_loss: 0.0550 - rpn_bbox_loss: 0.3207 - mrcnn_class_loss: 0.3903 - mrcnn_bbox_loss: 0.1234 - mrcnn_mask_loss: 0.3190 - val_loss: 1.3496 - val_rpn_class_loss: 0.1135 - val_rpn_bbox_loss: 0.3477 - val_mrcnn_class_loss: 0.4072 - val_mrcnn_bbox_loss: 0.1494 - val_mrcnn_mask_loss: 0.3319\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 56s 6s/step - loss: 1.2067 - rpn_class_loss: 0.0496 - rpn_bbox_loss: 0.3158 - mrcnn_class_loss: 0.3957 - mrcnn_bbox_loss: 0.1276 - mrcnn_mask_loss: 0.3178 - val_loss: 1.3568 - val_rpn_class_loss: 0.1015 - val_rpn_bbox_loss: 0.3437 - val_mrcnn_class_loss: 0.4370 - val_mrcnn_bbox_loss: 0.1451 - val_mrcnn_mask_loss: 0.3295\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 44s 4s/step - loss: 1.2035 - rpn_class_loss: 0.0315 - rpn_bbox_loss: 0.2992 - mrcnn_class_loss: 0.4121 - mrcnn_bbox_loss: 0.1460 - mrcnn_mask_loss: 0.3146 - val_loss: 1.2825 - val_rpn_class_loss: 0.0560 - val_rpn_bbox_loss: 0.3288 - val_mrcnn_class_loss: 0.4340 - val_mrcnn_bbox_loss: 0.1358 - val_mrcnn_mask_loss: 0.3280\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 29s 3s/step - loss: 1.1770 - rpn_class_loss: 0.0307 - rpn_bbox_loss: 0.2977 - mrcnn_class_loss: 0.3971 - mrcnn_bbox_loss: 0.1422 - mrcnn_mask_loss: 0.3093 - val_loss: 1.2489 - val_rpn_class_loss: 0.0554 - val_rpn_bbox_loss: 0.3286 - val_mrcnn_class_loss: 0.4084 - val_mrcnn_bbox_loss: 0.1325 - val_mrcnn_mask_loss: 0.3240\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 133s 13s/step - loss: 1.3285 - rpn_class_loss: 0.0725 - rpn_bbox_loss: 0.3495 - mrcnn_class_loss: 0.4308 - mrcnn_bbox_loss: 0.1503 - mrcnn_mask_loss: 0.3255 - val_loss: 1.2744 - val_rpn_class_loss: 0.0533 - val_rpn_bbox_loss: 0.3281 - val_mrcnn_class_loss: 0.4365 - val_mrcnn_bbox_loss: 0.1334 - val_mrcnn_mask_loss: 0.3231\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 1.3493 - rpn_class_loss: 0.0781 - rpn_bbox_loss: 0.3611 - mrcnn_class_loss: 0.4342 - mrcnn_bbox_loss: 0.1517 - mrcnn_mask_loss: 0.3241 - val_loss: 1.2519 - val_rpn_class_loss: 0.0505 - val_rpn_bbox_loss: 0.3274 - val_mrcnn_class_loss: 0.4104 - val_mrcnn_bbox_loss: 0.1369 - val_mrcnn_mask_loss: 0.3267\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 100s 10s/step - loss: 1.3366 - rpn_class_loss: 0.0689 - rpn_bbox_loss: 0.3663 - mrcnn_class_loss: 0.4197 - mrcnn_bbox_loss: 0.1512 - mrcnn_mask_loss: 0.3306 - val_loss: 1.3531 - val_rpn_class_loss: 0.1033 - val_rpn_bbox_loss: 0.3630 - val_mrcnn_class_loss: 0.4097 - val_mrcnn_bbox_loss: 0.1424 - val_mrcnn_mask_loss: 0.3347\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.3176 - rpn_class_loss: 0.0600 - rpn_bbox_loss: 0.3749 - mrcnn_class_loss: 0.3965 - mrcnn_bbox_loss: 0.1480 - mrcnn_mask_loss: 0.3382 - val_loss: 1.4820 - val_rpn_class_loss: 0.1828 - val_rpn_bbox_loss: 0.4167 - val_mrcnn_class_loss: 0.3965 - val_mrcnn_bbox_loss: 0.1478 - val_mrcnn_mask_loss: 0.3382\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 28s 3s/step - loss: 1.2862 - rpn_class_loss: 0.0577 - rpn_bbox_loss: 0.3731 - mrcnn_class_loss: 0.3718 - mrcnn_bbox_loss: 0.1475 - mrcnn_mask_loss: 0.3361 - val_loss: 1.4771 - val_rpn_class_loss: 0.1802 - val_rpn_bbox_loss: 0.4159 - val_mrcnn_class_loss: 0.3874 - val_mrcnn_bbox_loss: 0.1506 - val_mrcnn_mask_loss: 0.3429\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 174s 17s/step - loss: 1.3888 - rpn_class_loss: 0.1377 - rpn_bbox_loss: 0.3634 - mrcnn_class_loss: 0.4156 - mrcnn_bbox_loss: 0.1403 - mrcnn_mask_loss: 0.3318 - val_loss: 1.4850 - val_rpn_class_loss: 0.1712 - val_rpn_bbox_loss: 0.4145 - val_mrcnn_class_loss: 0.3991 - val_mrcnn_bbox_loss: 0.1527 - val_mrcnn_mask_loss: 0.3475\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.3646 - rpn_class_loss: 0.1238 - rpn_bbox_loss: 0.3607 - mrcnn_class_loss: 0.4121 - mrcnn_bbox_loss: 0.1385 - mrcnn_mask_loss: 0.3294 - val_loss: 1.4852 - val_rpn_class_loss: 0.1621 - val_rpn_bbox_loss: 0.4131 - val_mrcnn_class_loss: 0.4116 - val_mrcnn_bbox_loss: 0.1538 - val_mrcnn_mask_loss: 0.3447\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 31s 3s/step - loss: 1.2291 - rpn_class_loss: 0.0677 - rpn_bbox_loss: 0.3181 - mrcnn_class_loss: 0.3923 - mrcnn_bbox_loss: 0.1424 - mrcnn_mask_loss: 0.3085 - val_loss: 1.5016 - val_rpn_class_loss: 0.1348 - val_rpn_bbox_loss: 0.4018 - val_mrcnn_class_loss: 0.4697 - val_mrcnn_bbox_loss: 0.1518 - val_mrcnn_mask_loss: 0.3434\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 30s 3s/step - loss: 1.0908 - rpn_class_loss: 0.0355 - rpn_bbox_loss: 0.2899 - mrcnn_class_loss: 0.3387 - mrcnn_bbox_loss: 0.1397 - mrcnn_mask_loss: 0.2870 - val_loss: 1.4546 - val_rpn_class_loss: 0.1195 - val_rpn_bbox_loss: 0.3952 - val_mrcnn_class_loss: 0.4463 - val_mrcnn_bbox_loss: 0.1516 - val_mrcnn_mask_loss: 0.3422\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.1089 - rpn_class_loss: 0.0328 - rpn_bbox_loss: 0.2909 - mrcnn_class_loss: 0.3430 - mrcnn_bbox_loss: 0.1459 - mrcnn_mask_loss: 0.2963 - val_loss: 1.5103 - val_rpn_class_loss: 0.1196 - val_rpn_bbox_loss: 0.3956 - val_mrcnn_class_loss: 0.4859 - val_mrcnn_bbox_loss: 0.1579 - val_mrcnn_mask_loss: 0.3513\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 30s 3s/step - loss: 1.1588 - rpn_class_loss: 0.0239 - rpn_bbox_loss: 0.2994 - mrcnn_class_loss: 0.3668 - mrcnn_bbox_loss: 0.1504 - mrcnn_mask_loss: 0.3183 - val_loss: 1.4607 - val_rpn_class_loss: 0.1198 - val_rpn_bbox_loss: 0.3957 - val_mrcnn_class_loss: 0.4487 - val_mrcnn_bbox_loss: 0.1533 - val_mrcnn_mask_loss: 0.3433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "10/10 [==============================] - 48s 5s/step - loss: 1.1513 - rpn_class_loss: 0.0234 - rpn_bbox_loss: 0.2980 - mrcnn_class_loss: 0.3602 - mrcnn_bbox_loss: 0.1522 - mrcnn_mask_loss: 0.3175 - val_loss: 1.4732 - val_rpn_class_loss: 0.1199 - val_rpn_bbox_loss: 0.3958 - val_mrcnn_class_loss: 0.4680 - val_mrcnn_bbox_loss: 0.1499 - val_mrcnn_mask_loss: 0.3396\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 32s 3s/step - loss: 1.0873 - rpn_class_loss: 0.0271 - rpn_bbox_loss: 0.3088 - mrcnn_class_loss: 0.3082 - mrcnn_bbox_loss: 0.1462 - mrcnn_mask_loss: 0.2970 - val_loss: 1.4018 - val_rpn_class_loss: 0.1082 - val_rpn_bbox_loss: 0.3920 - val_mrcnn_class_loss: 0.4212 - val_mrcnn_bbox_loss: 0.1529 - val_mrcnn_mask_loss: 0.3274\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0678 - rpn_class_loss: 0.0276 - rpn_bbox_loss: 0.3104 - mrcnn_class_loss: 0.2896 - mrcnn_bbox_loss: 0.1454 - mrcnn_mask_loss: 0.2948 - val_loss: 1.3632 - val_rpn_class_loss: 0.1053 - val_rpn_bbox_loss: 0.3910 - val_mrcnn_class_loss: 0.3969 - val_mrcnn_bbox_loss: 0.1521 - val_mrcnn_mask_loss: 0.3179\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 115s 11s/step - loss: 1.1053 - rpn_class_loss: 0.0315 - rpn_bbox_loss: 0.3139 - mrcnn_class_loss: 0.3226 - mrcnn_bbox_loss: 0.1423 - mrcnn_mask_loss: 0.2950 - val_loss: 1.3631 - val_rpn_class_loss: 0.1052 - val_rpn_bbox_loss: 0.3908 - val_mrcnn_class_loss: 0.4031 - val_mrcnn_bbox_loss: 0.1497 - val_mrcnn_mask_loss: 0.3142\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.1446 - rpn_class_loss: 0.0375 - rpn_bbox_loss: 0.3207 - mrcnn_class_loss: 0.3523 - mrcnn_bbox_loss: 0.1387 - mrcnn_mask_loss: 0.2954 - val_loss: 1.3619 - val_rpn_class_loss: 0.1048 - val_rpn_bbox_loss: 0.3907 - val_mrcnn_class_loss: 0.4027 - val_mrcnn_bbox_loss: 0.1495 - val_mrcnn_mask_loss: 0.3142\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 48s 5s/step - loss: 1.1270 - rpn_class_loss: 0.0366 - rpn_bbox_loss: 0.3199 - mrcnn_class_loss: 0.3407 - mrcnn_bbox_loss: 0.1368 - mrcnn_mask_loss: 0.2930 - val_loss: 1.3629 - val_rpn_class_loss: 0.1044 - val_rpn_bbox_loss: 0.3907 - val_mrcnn_class_loss: 0.3996 - val_mrcnn_bbox_loss: 0.1519 - val_mrcnn_mask_loss: 0.3163\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 29s 3s/step - loss: 1.1185 - rpn_class_loss: 0.0319 - rpn_bbox_loss: 0.3052 - mrcnn_class_loss: 0.3461 - mrcnn_bbox_loss: 0.1412 - mrcnn_mask_loss: 0.2940 - val_loss: 1.2927 - val_rpn_class_loss: 0.0895 - val_rpn_bbox_loss: 0.3538 - val_mrcnn_class_loss: 0.4208 - val_mrcnn_bbox_loss: 0.1334 - val_mrcnn_mask_loss: 0.2953\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 30s 3s/step - loss: 1.1158 - rpn_class_loss: 0.0315 - rpn_bbox_loss: 0.3034 - mrcnn_class_loss: 0.3481 - mrcnn_bbox_loss: 0.1417 - mrcnn_mask_loss: 0.2912 - val_loss: 1.3186 - val_rpn_class_loss: 0.0897 - val_rpn_bbox_loss: 0.3537 - val_mrcnn_class_loss: 0.4404 - val_mrcnn_bbox_loss: 0.1356 - val_mrcnn_mask_loss: 0.2992\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 122s 12s/step - loss: 1.1676 - rpn_class_loss: 0.0603 - rpn_bbox_loss: 0.3253 - mrcnn_class_loss: 0.3551 - mrcnn_bbox_loss: 0.1368 - mrcnn_mask_loss: 0.2901 - val_loss: 1.2876 - val_rpn_class_loss: 0.0884 - val_rpn_bbox_loss: 0.3533 - val_mrcnn_class_loss: 0.4122 - val_mrcnn_bbox_loss: 0.1346 - val_mrcnn_mask_loss: 0.2991\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 1.1940 - rpn_class_loss: 0.0758 - rpn_bbox_loss: 0.3394 - mrcnn_class_loss: 0.3576 - mrcnn_bbox_loss: 0.1338 - mrcnn_mask_loss: 0.2875 - val_loss: 1.2925 - val_rpn_class_loss: 0.0855 - val_rpn_bbox_loss: 0.3525 - val_mrcnn_class_loss: 0.4204 - val_mrcnn_bbox_loss: 0.1357 - val_mrcnn_mask_loss: 0.2985\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 41s 4s/step - loss: 1.1426 - rpn_class_loss: 0.0619 - rpn_bbox_loss: 0.3264 - mrcnn_class_loss: 0.3283 - mrcnn_bbox_loss: 0.1379 - mrcnn_mask_loss: 0.2880 - val_loss: 1.2707 - val_rpn_class_loss: 0.0773 - val_rpn_bbox_loss: 0.3446 - val_mrcnn_class_loss: 0.4191 - val_mrcnn_bbox_loss: 0.1354 - val_mrcnn_mask_loss: 0.2943\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.9818 - rpn_class_loss: 0.0254 - rpn_bbox_loss: 0.2814 - mrcnn_class_loss: 0.2520 - mrcnn_bbox_loss: 0.1408 - mrcnn_mask_loss: 0.2821 - val_loss: 1.1235 - val_rpn_class_loss: 0.0539 - val_rpn_bbox_loss: 0.3160 - val_mrcnn_class_loss: 0.3457 - val_mrcnn_bbox_loss: 0.1290 - val_mrcnn_mask_loss: 0.2790\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.9678 - rpn_class_loss: 0.0240 - rpn_bbox_loss: 0.2795 - mrcnn_class_loss: 0.2448 - mrcnn_bbox_loss: 0.1405 - mrcnn_mask_loss: 0.2790 - val_loss: 1.1299 - val_rpn_class_loss: 0.0542 - val_rpn_bbox_loss: 0.3161 - val_mrcnn_class_loss: 0.3582 - val_mrcnn_bbox_loss: 0.1284 - val_mrcnn_mask_loss: 0.2730\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.9953 - rpn_class_loss: 0.0175 - rpn_bbox_loss: 0.2759 - mrcnn_class_loss: 0.2778 - mrcnn_bbox_loss: 0.1446 - mrcnn_mask_loss: 0.2796 - val_loss: 1.1198 - val_rpn_class_loss: 0.0544 - val_rpn_bbox_loss: 0.3162 - val_mrcnn_class_loss: 0.3578 - val_mrcnn_bbox_loss: 0.1234 - val_mrcnn_mask_loss: 0.2679\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 134s 13s/step - loss: 1.0317 - rpn_class_loss: 0.0190 - rpn_bbox_loss: 0.2825 - mrcnn_class_loss: 0.3016 - mrcnn_bbox_loss: 0.1455 - mrcnn_mask_loss: 0.2831 - val_loss: 1.1194 - val_rpn_class_loss: 0.0544 - val_rpn_bbox_loss: 0.3163 - val_mrcnn_class_loss: 0.3427 - val_mrcnn_bbox_loss: 0.1294 - val_mrcnn_mask_loss: 0.2766\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 47s 5s/step - loss: 1.1139 - rpn_class_loss: 0.0335 - rpn_bbox_loss: 0.3096 - mrcnn_class_loss: 0.3289 - mrcnn_bbox_loss: 0.1464 - mrcnn_mask_loss: 0.2956 - val_loss: 1.1276 - val_rpn_class_loss: 0.0527 - val_rpn_bbox_loss: 0.3207 - val_mrcnn_class_loss: 0.3418 - val_mrcnn_bbox_loss: 0.1329 - val_mrcnn_mask_loss: 0.2796\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 1.2691 - rpn_class_loss: 0.0565 - rpn_bbox_loss: 0.3561 - mrcnn_class_loss: 0.3887 - mrcnn_bbox_loss: 0.1473 - mrcnn_mask_loss: 0.3204 - val_loss: 1.1877 - val_rpn_class_loss: 0.0495 - val_rpn_bbox_loss: 0.3269 - val_mrcnn_class_loss: 0.3818 - val_mrcnn_bbox_loss: 0.1372 - val_mrcnn_mask_loss: 0.2923\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 50s 5s/step - loss: 1.2911 - rpn_class_loss: 0.0589 - rpn_bbox_loss: 0.3643 - mrcnn_class_loss: 0.3935 - mrcnn_bbox_loss: 0.1497 - mrcnn_mask_loss: 0.3246 - val_loss: 1.1659 - val_rpn_class_loss: 0.0485 - val_rpn_bbox_loss: 0.3262 - val_mrcnn_class_loss: 0.3695 - val_mrcnn_bbox_loss: 0.1336 - val_mrcnn_mask_loss: 0.2881\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 1.0305 - rpn_class_loss: 0.0331 - rpn_bbox_loss: 0.2952 - mrcnn_class_loss: 0.2894 - mrcnn_bbox_loss: 0.1332 - mrcnn_mask_loss: 0.2795 - val_loss: 1.1677 - val_rpn_class_loss: 0.0483 - val_rpn_bbox_loss: 0.3260 - val_mrcnn_class_loss: 0.3738 - val_mrcnn_bbox_loss: 0.1333 - val_mrcnn_mask_loss: 0.2863\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.0038 - rpn_class_loss: 0.0316 - rpn_bbox_loss: 0.2905 - mrcnn_class_loss: 0.2768 - mrcnn_bbox_loss: 0.1308 - mrcnn_mask_loss: 0.2740 - val_loss: 1.1560 - val_rpn_class_loss: 0.0484 - val_rpn_bbox_loss: 0.3259 - val_mrcnn_class_loss: 0.3606 - val_mrcnn_bbox_loss: 0.1365 - val_mrcnn_mask_loss: 0.2847\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 53s 5s/step - loss: 0.9650 - rpn_class_loss: 0.0271 - rpn_bbox_loss: 0.2762 - mrcnn_class_loss: 0.2706 - mrcnn_bbox_loss: 0.1279 - mrcnn_mask_loss: 0.2632 - val_loss: 1.3761 - val_rpn_class_loss: 0.1050 - val_rpn_bbox_loss: 0.3750 - val_mrcnn_class_loss: 0.4283 - val_mrcnn_bbox_loss: 0.1493 - val_mrcnn_mask_loss: 0.3185\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 116s 12s/step - loss: 0.9440 - rpn_class_loss: 0.0254 - rpn_bbox_loss: 0.2668 - mrcnn_class_loss: 0.2739 - mrcnn_bbox_loss: 0.1245 - mrcnn_mask_loss: 0.2534 - val_loss: 1.5196 - val_rpn_class_loss: 0.1426 - val_rpn_bbox_loss: 0.4078 - val_mrcnn_class_loss: 0.4695 - val_mrcnn_bbox_loss: 0.1582 - val_mrcnn_mask_loss: 0.3414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.9847 - rpn_class_loss: 0.0289 - rpn_bbox_loss: 0.2739 - mrcnn_class_loss: 0.2974 - mrcnn_bbox_loss: 0.1259 - mrcnn_mask_loss: 0.2585 - val_loss: 1.4945 - val_rpn_class_loss: 0.1423 - val_rpn_bbox_loss: 0.4078 - val_mrcnn_class_loss: 0.4507 - val_mrcnn_bbox_loss: 0.1556 - val_mrcnn_mask_loss: 0.3380\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 31s 3s/step - loss: 1.2368 - rpn_class_loss: 0.0540 - rpn_bbox_loss: 0.3313 - mrcnn_class_loss: 0.4141 - mrcnn_bbox_loss: 0.1457 - mrcnn_mask_loss: 0.2917 - val_loss: 1.5399 - val_rpn_class_loss: 0.1401 - val_rpn_bbox_loss: 0.4075 - val_mrcnn_class_loss: 0.4931 - val_mrcnn_bbox_loss: 0.1600 - val_mrcnn_mask_loss: 0.3391\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 1.2468 - rpn_class_loss: 0.0557 - rpn_bbox_loss: 0.3385 - mrcnn_class_loss: 0.4131 - mrcnn_bbox_loss: 0.1462 - mrcnn_mask_loss: 0.2933 - val_loss: 1.4670 - val_rpn_class_loss: 0.1374 - val_rpn_bbox_loss: 0.4071 - val_mrcnn_class_loss: 0.4307 - val_mrcnn_bbox_loss: 0.1580 - val_mrcnn_mask_loss: 0.3338\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 68s 7s/step - loss: 1.1705 - rpn_class_loss: 0.0523 - rpn_bbox_loss: 0.3358 - mrcnn_class_loss: 0.3540 - mrcnn_bbox_loss: 0.1376 - mrcnn_mask_loss: 0.2908 - val_loss: 1.2329 - val_rpn_class_loss: 0.0700 - val_rpn_bbox_loss: 0.3373 - val_mrcnn_class_loss: 0.3959 - val_mrcnn_bbox_loss: 0.1357 - val_mrcnn_mask_loss: 0.2940\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 54s 5s/step - loss: 1.1501 - rpn_class_loss: 0.0510 - rpn_bbox_loss: 0.3343 - mrcnn_class_loss: 0.3356 - mrcnn_bbox_loss: 0.1364 - mrcnn_mask_loss: 0.2929 - val_loss: 1.1364 - val_rpn_class_loss: 0.0533 - val_rpn_bbox_loss: 0.3196 - val_mrcnn_class_loss: 0.3633 - val_mrcnn_bbox_loss: 0.1261 - val_mrcnn_mask_loss: 0.2741\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 120s 12s/step - loss: 1.1230 - rpn_class_loss: 0.0429 - rpn_bbox_loss: 0.3283 - mrcnn_class_loss: 0.3334 - mrcnn_bbox_loss: 0.1302 - mrcnn_mask_loss: 0.2883 - val_loss: 1.1544 - val_rpn_class_loss: 0.0532 - val_rpn_bbox_loss: 0.3194 - val_mrcnn_class_loss: 0.3724 - val_mrcnn_bbox_loss: 0.1292 - val_mrcnn_mask_loss: 0.2801\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 47s 5s/step - loss: 1.1032 - rpn_class_loss: 0.0316 - rpn_bbox_loss: 0.3202 - mrcnn_class_loss: 0.3491 - mrcnn_bbox_loss: 0.1202 - mrcnn_mask_loss: 0.2821 - val_loss: 1.1882 - val_rpn_class_loss: 0.0706 - val_rpn_bbox_loss: 0.3478 - val_mrcnn_class_loss: 0.3595 - val_mrcnn_bbox_loss: 0.1321 - val_mrcnn_mask_loss: 0.2783\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 66s 7s/step - loss: 1.1107 - rpn_class_loss: 0.0309 - rpn_bbox_loss: 0.3194 - mrcnn_class_loss: 0.3542 - mrcnn_bbox_loss: 0.1226 - mrcnn_mask_loss: 0.2835 - val_loss: 1.2122 - val_rpn_class_loss: 0.0705 - val_rpn_bbox_loss: 0.3477 - val_mrcnn_class_loss: 0.3724 - val_mrcnn_bbox_loss: 0.1368 - val_mrcnn_mask_loss: 0.2849\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.9838 - rpn_class_loss: 0.0257 - rpn_bbox_loss: 0.2879 - mrcnn_class_loss: 0.2752 - mrcnn_bbox_loss: 0.1277 - mrcnn_mask_loss: 0.2673 - val_loss: 1.2316 - val_rpn_class_loss: 0.0793 - val_rpn_bbox_loss: 0.3618 - val_mrcnn_class_loss: 0.3705 - val_mrcnn_bbox_loss: 0.1391 - val_mrcnn_mask_loss: 0.2809\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.9865 - rpn_class_loss: 0.0313 - rpn_bbox_loss: 0.2889 - mrcnn_class_loss: 0.2685 - mrcnn_bbox_loss: 0.1293 - mrcnn_mask_loss: 0.2685 - val_loss: 1.2859 - val_rpn_class_loss: 0.0881 - val_rpn_bbox_loss: 0.3759 - val_mrcnn_class_loss: 0.3954 - val_mrcnn_bbox_loss: 0.1433 - val_mrcnn_mask_loss: 0.2832\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 32s 3s/step - loss: 1.0013 - rpn_class_loss: 0.0399 - rpn_bbox_loss: 0.2916 - mrcnn_class_loss: 0.2709 - mrcnn_bbox_loss: 0.1309 - mrcnn_mask_loss: 0.2680 - val_loss: 1.2726 - val_rpn_class_loss: 0.0880 - val_rpn_bbox_loss: 0.3759 - val_mrcnn_class_loss: 0.3872 - val_mrcnn_bbox_loss: 0.1426 - val_mrcnn_mask_loss: 0.2788\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 78s 8s/step - loss: 1.0292 - rpn_class_loss: 0.0528 - rpn_bbox_loss: 0.3003 - mrcnn_class_loss: 0.2701 - mrcnn_bbox_loss: 0.1364 - mrcnn_mask_loss: 0.2696 - val_loss: 1.3114 - val_rpn_class_loss: 0.1040 - val_rpn_bbox_loss: 0.3970 - val_mrcnn_class_loss: 0.3713 - val_mrcnn_bbox_loss: 0.1473 - val_mrcnn_mask_loss: 0.2918\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 1.0664 - rpn_class_loss: 0.0600 - rpn_bbox_loss: 0.3144 - mrcnn_class_loss: 0.2809 - mrcnn_bbox_loss: 0.1375 - mrcnn_mask_loss: 0.2737 - val_loss: 1.3945 - val_rpn_class_loss: 0.1255 - val_rpn_bbox_loss: 0.4178 - val_mrcnn_class_loss: 0.3863 - val_mrcnn_bbox_loss: 0.1520 - val_mrcnn_mask_loss: 0.3129\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 40s 4s/step - loss: 1.1116 - rpn_class_loss: 0.0652 - rpn_bbox_loss: 0.3318 - mrcnn_class_loss: 0.2938 - mrcnn_bbox_loss: 0.1413 - mrcnn_mask_loss: 0.2796 - val_loss: 1.3344 - val_rpn_class_loss: 0.1095 - val_rpn_bbox_loss: 0.4033 - val_mrcnn_class_loss: 0.3734 - val_mrcnn_bbox_loss: 0.1492 - val_mrcnn_mask_loss: 0.2991\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 1.1101 - rpn_class_loss: 0.0648 - rpn_bbox_loss: 0.3346 - mrcnn_class_loss: 0.2916 - mrcnn_bbox_loss: 0.1385 - mrcnn_mask_loss: 0.2807 - val_loss: 1.4041 - val_rpn_class_loss: 0.1220 - val_rpn_bbox_loss: 0.4164 - val_mrcnn_class_loss: 0.3890 - val_mrcnn_bbox_loss: 0.1581 - val_mrcnn_mask_loss: 0.3187\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 69s 7s/step - loss: 1.0975 - rpn_class_loss: 0.0508 - rpn_bbox_loss: 0.3358 - mrcnn_class_loss: 0.2870 - mrcnn_bbox_loss: 0.1442 - mrcnn_mask_loss: 0.2798 - val_loss: 1.3574 - val_rpn_class_loss: 0.1126 - val_rpn_bbox_loss: 0.4070 - val_mrcnn_class_loss: 0.3755 - val_mrcnn_bbox_loss: 0.1524 - val_mrcnn_mask_loss: 0.3099\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 45s 4s/step - loss: 1.0924 - rpn_class_loss: 0.0467 - rpn_bbox_loss: 0.3344 - mrcnn_class_loss: 0.2852 - mrcnn_bbox_loss: 0.1469 - mrcnn_mask_loss: 0.2791 - val_loss: 1.4063 - val_rpn_class_loss: 0.1276 - val_rpn_bbox_loss: 0.4223 - val_mrcnn_class_loss: 0.3804 - val_mrcnn_bbox_loss: 0.1568 - val_mrcnn_mask_loss: 0.3191\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 50s 5s/step - loss: 1.0315 - rpn_class_loss: 0.0422 - rpn_bbox_loss: 0.3113 - mrcnn_class_loss: 0.2794 - mrcnn_bbox_loss: 0.1355 - mrcnn_mask_loss: 0.2631 - val_loss: 1.2022 - val_rpn_class_loss: 0.0668 - val_rpn_bbox_loss: 0.3595 - val_mrcnn_class_loss: 0.3528 - val_mrcnn_bbox_loss: 0.1378 - val_mrcnn_mask_loss: 0.2855\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 39s 4s/step - loss: 0.9431 - rpn_class_loss: 0.0358 - rpn_bbox_loss: 0.2773 - mrcnn_class_loss: 0.2664 - mrcnn_bbox_loss: 0.1172 - mrcnn_mask_loss: 0.2463 - val_loss: 1.3366 - val_rpn_class_loss: 0.0975 - val_rpn_bbox_loss: 0.3909 - val_mrcnn_class_loss: 0.3838 - val_mrcnn_bbox_loss: 0.1536 - val_mrcnn_mask_loss: 0.3109\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 32s 3s/step - loss: 0.9394 - rpn_class_loss: 0.0338 - rpn_bbox_loss: 0.2746 - mrcnn_class_loss: 0.2684 - mrcnn_bbox_loss: 0.1165 - mrcnn_mask_loss: 0.2462 - val_loss: 1.1533 - val_rpn_class_loss: 0.0519 - val_rpn_bbox_loss: 0.3440 - val_mrcnn_class_loss: 0.3393 - val_mrcnn_bbox_loss: 0.1371 - val_mrcnn_mask_loss: 0.2810\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.8902 - rpn_class_loss: 0.0292 - rpn_bbox_loss: 0.2689 - mrcnn_class_loss: 0.2390 - mrcnn_bbox_loss: 0.1129 - mrcnn_mask_loss: 0.2402 - val_loss: 1.1661 - val_rpn_class_loss: 0.0520 - val_rpn_bbox_loss: 0.3440 - val_mrcnn_class_loss: 0.3519 - val_mrcnn_bbox_loss: 0.1389 - val_mrcnn_mask_loss: 0.2793\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.8990 - rpn_class_loss: 0.0280 - rpn_bbox_loss: 0.2720 - mrcnn_class_loss: 0.2447 - mrcnn_bbox_loss: 0.1110 - mrcnn_mask_loss: 0.2433 - val_loss: 1.1887 - val_rpn_class_loss: 0.0569 - val_rpn_bbox_loss: 0.3478 - val_mrcnn_class_loss: 0.3603 - val_mrcnn_bbox_loss: 0.1355 - val_mrcnn_mask_loss: 0.2882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      "10/10 [==============================] - 52s 5s/step - loss: 1.0430 - rpn_class_loss: 0.0310 - rpn_bbox_loss: 0.3001 - mrcnn_class_loss: 0.3168 - mrcnn_bbox_loss: 0.1267 - mrcnn_mask_loss: 0.2683 - val_loss: 1.2365 - val_rpn_class_loss: 0.0666 - val_rpn_bbox_loss: 0.3551 - val_mrcnn_class_loss: 0.3834 - val_mrcnn_bbox_loss: 0.1367 - val_mrcnn_mask_loss: 0.2947\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 1.1278 - rpn_class_loss: 0.0327 - rpn_bbox_loss: 0.3170 - mrcnn_class_loss: 0.3539 - mrcnn_bbox_loss: 0.1372 - mrcnn_mask_loss: 0.2871 - val_loss: 1.2451 - val_rpn_class_loss: 0.0714 - val_rpn_bbox_loss: 0.3585 - val_mrcnn_class_loss: 0.3710 - val_mrcnn_bbox_loss: 0.1395 - val_mrcnn_mask_loss: 0.3046\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 96s 10s/step - loss: 1.1629 - rpn_class_loss: 0.0386 - rpn_bbox_loss: 0.3283 - mrcnn_class_loss: 0.3642 - mrcnn_bbox_loss: 0.1394 - mrcnn_mask_loss: 0.2923 - val_loss: 1.2889 - val_rpn_class_loss: 0.0760 - val_rpn_bbox_loss: 0.3619 - val_mrcnn_class_loss: 0.4002 - val_mrcnn_bbox_loss: 0.1428 - val_mrcnn_mask_loss: 0.3081\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 65s 6s/step - loss: 1.2255 - rpn_class_loss: 0.0608 - rpn_bbox_loss: 0.3528 - mrcnn_class_loss: 0.3677 - mrcnn_bbox_loss: 0.1432 - mrcnn_mask_loss: 0.3010 - val_loss: 1.2848 - val_rpn_class_loss: 0.0750 - val_rpn_bbox_loss: 0.3617 - val_mrcnn_class_loss: 0.3965 - val_mrcnn_bbox_loss: 0.1406 - val_mrcnn_mask_loss: 0.3110\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 48s 5s/step - loss: 1.2200 - rpn_class_loss: 0.0589 - rpn_bbox_loss: 0.3518 - mrcnn_class_loss: 0.3647 - mrcnn_bbox_loss: 0.1431 - mrcnn_mask_loss: 0.3015 - val_loss: 1.2635 - val_rpn_class_loss: 0.0726 - val_rpn_bbox_loss: 0.3600 - val_mrcnn_class_loss: 0.3897 - val_mrcnn_bbox_loss: 0.1393 - val_mrcnn_mask_loss: 0.3019\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 16s 2s/step - loss: 1.0409 - rpn_class_loss: 0.0430 - rpn_bbox_loss: 0.3137 - mrcnn_class_loss: 0.2794 - mrcnn_bbox_loss: 0.1313 - mrcnn_mask_loss: 0.2735 - val_loss: 1.2554 - val_rpn_class_loss: 0.0697 - val_rpn_bbox_loss: 0.3569 - val_mrcnn_class_loss: 0.3879 - val_mrcnn_bbox_loss: 0.1435 - val_mrcnn_mask_loss: 0.2974\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 63s 6s/step - loss: 1.0250 - rpn_class_loss: 0.0379 - rpn_bbox_loss: 0.3080 - mrcnn_class_loss: 0.2786 - mrcnn_bbox_loss: 0.1302 - mrcnn_mask_loss: 0.2704 - val_loss: 1.2385 - val_rpn_class_loss: 0.0670 - val_rpn_bbox_loss: 0.3538 - val_mrcnn_class_loss: 0.3933 - val_mrcnn_bbox_loss: 0.1426 - val_mrcnn_mask_loss: 0.2819\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 45s 5s/step - loss: 1.0863 - rpn_class_loss: 0.0362 - rpn_bbox_loss: 0.3147 - mrcnn_class_loss: 0.3180 - mrcnn_bbox_loss: 0.1383 - mrcnn_mask_loss: 0.2791 - val_loss: 1.2527 - val_rpn_class_loss: 0.0669 - val_rpn_bbox_loss: 0.3537 - val_mrcnn_class_loss: 0.3950 - val_mrcnn_bbox_loss: 0.1481 - val_mrcnn_mask_loss: 0.2890\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.1031 - rpn_class_loss: 0.0351 - rpn_bbox_loss: 0.3192 - mrcnn_class_loss: 0.3280 - mrcnn_bbox_loss: 0.1390 - mrcnn_mask_loss: 0.2817 - val_loss: 1.2585 - val_rpn_class_loss: 0.1006 - val_rpn_bbox_loss: 0.3666 - val_mrcnn_class_loss: 0.3588 - val_mrcnn_bbox_loss: 0.1459 - val_mrcnn_mask_loss: 0.2866\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 74s 7s/step - loss: 1.1342 - rpn_class_loss: 0.0320 - rpn_bbox_loss: 0.3188 - mrcnn_class_loss: 0.3498 - mrcnn_bbox_loss: 0.1461 - mrcnn_mask_loss: 0.2875 - val_loss: 1.2565 - val_rpn_class_loss: 0.1007 - val_rpn_bbox_loss: 0.3665 - val_mrcnn_class_loss: 0.3615 - val_mrcnn_bbox_loss: 0.1443 - val_mrcnn_mask_loss: 0.2835\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 45s 4s/step - loss: 1.0427 - rpn_class_loss: 0.0269 - rpn_bbox_loss: 0.2960 - mrcnn_class_loss: 0.2990 - mrcnn_bbox_loss: 0.1415 - mrcnn_mask_loss: 0.2792 - val_loss: 1.2616 - val_rpn_class_loss: 0.1236 - val_rpn_bbox_loss: 0.3749 - val_mrcnn_class_loss: 0.3313 - val_mrcnn_bbox_loss: 0.1468 - val_mrcnn_mask_loss: 0.2850\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 50s 5s/step - loss: 1.0200 - rpn_class_loss: 0.0259 - rpn_bbox_loss: 0.2892 - mrcnn_class_loss: 0.2920 - mrcnn_bbox_loss: 0.1389 - mrcnn_mask_loss: 0.2739 - val_loss: 1.2531 - val_rpn_class_loss: 0.1014 - val_rpn_bbox_loss: 0.3664 - val_mrcnn_class_loss: 0.3523 - val_mrcnn_bbox_loss: 0.1466 - val_mrcnn_mask_loss: 0.2865\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 39s 4s/step - loss: 1.0008 - rpn_class_loss: 0.0306 - rpn_bbox_loss: 0.2957 - mrcnn_class_loss: 0.2650 - mrcnn_bbox_loss: 0.1389 - mrcnn_mask_loss: 0.2705 - val_loss: 1.2425 - val_rpn_class_loss: 0.0903 - val_rpn_bbox_loss: 0.3623 - val_mrcnn_class_loss: 0.3577 - val_mrcnn_bbox_loss: 0.1461 - val_mrcnn_mask_loss: 0.2860\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 119s 12s/step - loss: 1.0290 - rpn_class_loss: 0.0376 - rpn_bbox_loss: 0.3051 - mrcnn_class_loss: 0.2782 - mrcnn_bbox_loss: 0.1393 - mrcnn_mask_loss: 0.2688 - val_loss: 1.1935 - val_rpn_class_loss: 0.0818 - val_rpn_bbox_loss: 0.3520 - val_mrcnn_class_loss: 0.3380 - val_mrcnn_bbox_loss: 0.1436 - val_mrcnn_mask_loss: 0.2781\n"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "# RegEx: \"heads\": r\"(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\"\n",
    "#start_train = time.time()\n",
    "heads_training_epochs = 100\n",
    "config.LEARNING_MOMENTUM = 0.7\n",
    "config.LEARNING_RATE = 0.0001\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=heads_training_epochs, \n",
    "            layers='heads'#,\n",
    "            #custom_callbacks=[mean_f1_callback]\n",
    "           )\n",
    "            #augmentation=augmentation) # unfreeze head and just train on last layer\n",
    "#end_train = time.time()\n",
    "#minutes = round((end_train - start_train) / 60, 2)\n",
    "#print(f'Heads training for {heads_training_epochs} epochs took {minutes} minutes')\n",
    "\n",
    "#Save temporary model\n",
    "#MB, Jan 11, 2022\n",
    "#tmp_model_path = os.path.join(coco.ROOT_DIR, \"on_axon_mrcnn_r50_heads_E12.h5\")\n",
    "#model.keras_model.save_weights(tmp_model_path)\n",
    "#model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6373c",
   "metadata": {},
   "source": [
    "## Fine tune ResNet Stage 5 and up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e893e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune layers from ResNet stage 5 and up\n",
    "# RegEx: \"5+\": r\"(res5.*)|(bn5.*)|(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\" in model.py\n",
    "print(\"Fine tune Resnet stage 5 and up\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=55,\n",
    "            layers='5+')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a8adb",
   "metadata": {},
   "source": [
    "## Fine tune ResNet Stage 4 and up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50910586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training notes: e56-e70 with LEARNING_RATE (55%--1% mAP improvement); \n",
    "#e71-80-105-130 with LEARNING_RATE * 2 (60%--5% improvement);\n",
    "#e130-e150: LR * 4; LM = 0.6(60%--0% improvement); \n",
    "#e151-175-LR*4, LM=0.7 (63%--mAP increase 3%)\n",
    "#e176-e185--LR*4, LM=0.8 (62% - mAP decrease 1%)\n",
    "#e186-e199-- (same) (63%)\n",
    "#e200-e219 -- (same) (steady around 63%)\n",
    "#e220-e229 -- LR*4, LM=0.9 (64.49%)\n",
    "#e230-e239 -- LR*6, LM=0.9 (67.98%)\n",
    "#e240-e249 -- LR*8, LM=0.9 (67.24%)\n",
    "#e250-e259 -- LR*8, LM=0.9 (68.24%)\n",
    "#e260-e265-e269 -- LR*10, LM=0.9 (69.03%)\n",
    "#To try later: exxx with LEARNING_RATE * 1 and LEARNING_MOMENTUM increased from 0.7 to 0.9\n",
    "#\n",
    "print(\"Fine tune Resnet stage 4 and up\")\n",
    "config.LEARNING_MOMENTUM = 0.9\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE*10,\n",
    "            epochs=25,\n",
    "            layers='4+',\n",
    "            custom_callbacks=[mean_f1_callback]\n",
    "           )\n",
    "            #augmentation=augmentation)\n",
    "        \n",
    "#Saving after training \"4+\" layers\n",
    "#MB, Jan 11, 2022\n",
    "#tmp_model_path = os.path.join(coco.ROOT_DIR, \"on_axon_mrcnn_r50_4up_E20.h5\")\n",
    "#model.keras_model.save_weights(tmp_model_path)\n",
    "#model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d717fe",
   "metadata": {},
   "source": [
    "## Fine tune 3+ layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#e379-e389: lr=*30; lm=0.8 -- 71.45%\n",
    "#e389-e405-419: lr=*30; lm=0.9 -- 73.11%\n",
    "#Note:\n",
    "# With #RPN_NMS_THRESHOLD = 0.9; increased from 0.7 to increase number of RPN proposals\n",
    "#       DETECTION_MIN_CONFIDENCE = 0.5; decreased from 0.7 to increase the number of detections\n",
    "#       DETECTION_NMS_THRESHOLD = 0.3\n",
    "#e395: lr=*30, lm=0.9 -- 77.09% (e395); so keeping these inference parameters for further inspection\n",
    "#e396-419: lr=*30, lm=0.9 -- 76.06%\n",
    "#e420-425-439-449: lr=*100, lm=0.7 -- 75.1%-76.24%\n",
    "\n",
    "print(\"Fine tune Resnet stage 3 and up\")\n",
    "config.LEARNING_MOMENTUM = 0.7\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE*100,\n",
    "            epochs=449,\n",
    "            layers='3+',\n",
    "            custom_callbacks=[mean_f1_callback]\n",
    "           )\n",
    "            #augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba9c4aa",
   "metadata": {},
   "source": [
    "## 3+ RPN layers with updated INFERENCE PARAMTERS; specifically, RPN_NMS_THRESHOLD = 0.9; DETECTION_MIN_CONFIDENCE = 0.5; DETECTION_NMS_THRESHOLD = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db69d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#e450-e459: lr=*3; lm=0.7 -- 74.78%\n",
    "#e459-e479: lr*3; lm=0.9 -- 75.32% (e479)\n",
    "print(\"Fine tune Resnet stage 3 and up\")\n",
    "config.LEARNING_MOMENTUM = 0.9\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE*3,\n",
    "            epochs=479,\n",
    "            layers='3+',\n",
    "            custom_callbacks=[mean_f1_callback]\n",
    "           )\n",
    "            #augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6294055c",
   "metadata": {},
   "source": [
    "## Lowering DETECTION_MIN_CONFIDENCE from 0.7 to 0.5 gave mAP ~ 77%.  But visually, this causes double labeling (see COCO Annotator validation images -- in M6800 laptop).  So, resetting to 0.7 and beginning \"all\" training from e395; april 21: increasing further to 0.9 to reduce double labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca4d97f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tune all layers\n",
      "\n",
      "Starting at epoch 100. LR=0.0001. LM=0.7.\n",
      "\n",
      "Checkpoint Path: /home/madhu/Lab/Members/00_madhu/Programs/axon_segmentation/logs/coco20230416T1607/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/envs/venv_mamba/envs/venv_maskrcnn/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/125\n",
      "10/10 [==============================] - 342s 34s/step - loss: 1.0945 - rpn_class_loss: 0.0686 - rpn_bbox_loss: 0.3402 - mrcnn_class_loss: 0.2783 - mrcnn_bbox_loss: 0.1365 - mrcnn_mask_loss: 0.2710 - val_loss: 1.3758 - val_rpn_class_loss: 0.1356 - val_rpn_bbox_loss: 0.3766 - val_mrcnn_class_loss: 0.4197 - val_mrcnn_bbox_loss: 0.1502 - val_mrcnn_mask_loss: 0.2936\n",
      "Epoch 102/125\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.0698 - rpn_class_loss: 0.0596 - rpn_bbox_loss: 0.3344 - mrcnn_class_loss: 0.2726 - mrcnn_bbox_loss: 0.1358 - mrcnn_mask_loss: 0.2674 - val_loss: 1.3369 - val_rpn_class_loss: 0.1313 - val_rpn_bbox_loss: 0.3745 - val_mrcnn_class_loss: 0.3939 - val_mrcnn_bbox_loss: 0.1447 - val_mrcnn_mask_loss: 0.2925\n",
      "Epoch 103/125\n",
      "10/10 [==============================] - 29s 3s/step - loss: 1.1036 - rpn_class_loss: 0.0419 - rpn_bbox_loss: 0.3347 - mrcnn_class_loss: 0.3141 - mrcnn_bbox_loss: 0.1316 - mrcnn_mask_loss: 0.2812 - val_loss: 1.3425 - val_rpn_class_loss: 0.1322 - val_rpn_bbox_loss: 0.3736 - val_mrcnn_class_loss: 0.3944 - val_mrcnn_bbox_loss: 0.1477 - val_mrcnn_mask_loss: 0.2946\n",
      "Epoch 104/125\n",
      "10/10 [==============================] - 18s 2s/step - loss: 1.1060 - rpn_class_loss: 0.0312 - rpn_bbox_loss: 0.3344 - mrcnn_class_loss: 0.3213 - mrcnn_bbox_loss: 0.1287 - mrcnn_mask_loss: 0.2906 - val_loss: 1.3432 - val_rpn_class_loss: 0.1364 - val_rpn_bbox_loss: 0.3734 - val_mrcnn_class_loss: 0.3963 - val_mrcnn_bbox_loss: 0.1462 - val_mrcnn_mask_loss: 0.2909\n",
      "Epoch 105/125\n",
      "10/10 [==============================] - 106s 11s/step - loss: 1.0700 - rpn_class_loss: 0.0297 - rpn_bbox_loss: 0.3182 - mrcnn_class_loss: 0.3156 - mrcnn_bbox_loss: 0.1258 - mrcnn_mask_loss: 0.2805 - val_loss: 1.3324 - val_rpn_class_loss: 0.1324 - val_rpn_bbox_loss: 0.3762 - val_mrcnn_class_loss: 0.3899 - val_mrcnn_bbox_loss: 0.1446 - val_mrcnn_mask_loss: 0.2893\n",
      "Epoch 106/125\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.9706 - rpn_class_loss: 0.0325 - rpn_bbox_loss: 0.2654 - mrcnn_class_loss: 0.2921 - mrcnn_bbox_loss: 0.1284 - mrcnn_mask_loss: 0.2522 - val_loss: 1.2882 - val_rpn_class_loss: 0.1062 - val_rpn_bbox_loss: 0.3881 - val_mrcnn_class_loss: 0.3410 - val_mrcnn_bbox_loss: 0.1506 - val_mrcnn_mask_loss: 0.3024\n",
      "Epoch 107/125\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.9382 - rpn_class_loss: 0.0300 - rpn_bbox_loss: 0.2620 - mrcnn_class_loss: 0.2687 - mrcnn_bbox_loss: 0.1267 - mrcnn_mask_loss: 0.2508 - val_loss: 1.2665 - val_rpn_class_loss: 0.1071 - val_rpn_bbox_loss: 0.3883 - val_mrcnn_class_loss: 0.3320 - val_mrcnn_bbox_loss: 0.1464 - val_mrcnn_mask_loss: 0.2926\n",
      "Epoch 108/125\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.9037 - rpn_class_loss: 0.0335 - rpn_bbox_loss: 0.2537 - mrcnn_class_loss: 0.2646 - mrcnn_bbox_loss: 0.1129 - mrcnn_mask_loss: 0.2390 - val_loss: 1.2860 - val_rpn_class_loss: 0.1071 - val_rpn_bbox_loss: 0.3879 - val_mrcnn_class_loss: 0.3410 - val_mrcnn_bbox_loss: 0.1501 - val_mrcnn_mask_loss: 0.2999\n",
      "Epoch 109/125\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.8893 - rpn_class_loss: 0.0335 - rpn_bbox_loss: 0.2482 - mrcnn_class_loss: 0.2644 - mrcnn_bbox_loss: 0.1094 - mrcnn_mask_loss: 0.2338 - val_loss: 1.2704 - val_rpn_class_loss: 0.1068 - val_rpn_bbox_loss: 0.3874 - val_mrcnn_class_loss: 0.3321 - val_mrcnn_bbox_loss: 0.1479 - val_mrcnn_mask_loss: 0.2963\n",
      "Epoch 110/125\n",
      "10/10 [==============================] - 88s 9s/step - loss: 0.9287 - rpn_class_loss: 0.0283 - rpn_bbox_loss: 0.2805 - mrcnn_class_loss: 0.2528 - mrcnn_bbox_loss: 0.1194 - mrcnn_mask_loss: 0.2477 - val_loss: 1.1608 - val_rpn_class_loss: 0.0779 - val_rpn_bbox_loss: 0.3508 - val_mrcnn_class_loss: 0.3171 - val_mrcnn_bbox_loss: 0.1402 - val_mrcnn_mask_loss: 0.2748\n",
      "Epoch 111/125\n",
      "10/10 [==============================] - 20s 2s/step - loss: 1.0113 - rpn_class_loss: 0.0210 - rpn_bbox_loss: 0.3301 - mrcnn_class_loss: 0.2609 - mrcnn_bbox_loss: 0.1358 - mrcnn_mask_loss: 0.2634 - val_loss: 1.0198 - val_rpn_class_loss: 0.0347 - val_rpn_bbox_loss: 0.2955 - val_mrcnn_class_loss: 0.2929 - val_mrcnn_bbox_loss: 0.1400 - val_mrcnn_mask_loss: 0.2567\n",
      "Epoch 112/125\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.9883 - rpn_class_loss: 0.0190 - rpn_bbox_loss: 0.3246 - mrcnn_class_loss: 0.2439 - mrcnn_bbox_loss: 0.1354 - mrcnn_mask_loss: 0.2654 - val_loss: 1.0273 - val_rpn_class_loss: 0.0344 - val_rpn_bbox_loss: 0.2946 - val_mrcnn_class_loss: 0.3084 - val_mrcnn_bbox_loss: 0.1338 - val_mrcnn_mask_loss: 0.2561\n",
      "Epoch 113/125\n",
      "10/10 [==============================] - 189s 19s/step - loss: 1.1843 - rpn_class_loss: 0.0505 - rpn_bbox_loss: 0.3514 - mrcnn_class_loss: 0.3479 - mrcnn_bbox_loss: 0.1505 - mrcnn_mask_loss: 0.2840 - val_loss: 1.0078 - val_rpn_class_loss: 0.0341 - val_rpn_bbox_loss: 0.2920 - val_mrcnn_class_loss: 0.2878 - val_mrcnn_bbox_loss: 0.1380 - val_mrcnn_mask_loss: 0.2558\n",
      "Epoch 114/125\n",
      "10/10 [==============================] - 18s 2s/step - loss: 1.1356 - rpn_class_loss: 0.0412 - rpn_bbox_loss: 0.3463 - mrcnn_class_loss: 0.3207 - mrcnn_bbox_loss: 0.1450 - mrcnn_mask_loss: 0.2824 - val_loss: 1.0195 - val_rpn_class_loss: 0.0341 - val_rpn_bbox_loss: 0.2902 - val_mrcnn_class_loss: 0.3076 - val_mrcnn_bbox_loss: 0.1333 - val_mrcnn_mask_loss: 0.2542\n",
      "Epoch 115/125\n",
      "10/10 [==============================] - 91s 9s/step - loss: 1.0218 - rpn_class_loss: 0.0317 - rpn_bbox_loss: 0.3042 - mrcnn_class_loss: 0.2816 - mrcnn_bbox_loss: 0.1369 - mrcnn_mask_loss: 0.2674 - val_loss: 1.1669 - val_rpn_class_loss: 0.0545 - val_rpn_bbox_loss: 0.3310 - val_mrcnn_class_loss: 0.3563 - val_mrcnn_bbox_loss: 0.1416 - val_mrcnn_mask_loss: 0.2836\n",
      "Epoch 116/125\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.9131 - rpn_class_loss: 0.0266 - rpn_bbox_loss: 0.2758 - mrcnn_class_loss: 0.2374 - mrcnn_bbox_loss: 0.1221 - mrcnn_mask_loss: 0.2512 - val_loss: 1.2630 - val_rpn_class_loss: 0.0703 - val_rpn_bbox_loss: 0.3581 - val_mrcnn_class_loss: 0.3945 - val_mrcnn_bbox_loss: 0.1407 - val_mrcnn_mask_loss: 0.2994\n",
      "Epoch 117/125\n",
      "10/10 [==============================] - 95s 10s/step - loss: 0.9213 - rpn_class_loss: 0.0274 - rpn_bbox_loss: 0.2757 - mrcnn_class_loss: 0.2430 - mrcnn_bbox_loss: 0.1238 - mrcnn_mask_loss: 0.2515 - val_loss: 1.2619 - val_rpn_class_loss: 0.0719 - val_rpn_bbox_loss: 0.3578 - val_mrcnn_class_loss: 0.3949 - val_mrcnn_bbox_loss: 0.1397 - val_mrcnn_mask_loss: 0.2975\n",
      "Epoch 118/125\n",
      "10/10 [==============================] - 25s 3s/step - loss: 1.0033 - rpn_class_loss: 0.0364 - rpn_bbox_loss: 0.2853 - mrcnn_class_loss: 0.2837 - mrcnn_bbox_loss: 0.1324 - mrcnn_mask_loss: 0.2656 - val_loss: 1.2658 - val_rpn_class_loss: 0.0741 - val_rpn_bbox_loss: 0.3578 - val_mrcnn_class_loss: 0.3931 - val_mrcnn_bbox_loss: 0.1413 - val_mrcnn_mask_loss: 0.2993\n",
      "Epoch 119/125\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.9677 - rpn_class_loss: 0.0343 - rpn_bbox_loss: 0.2811 - mrcnn_class_loss: 0.2608 - mrcnn_bbox_loss: 0.1290 - mrcnn_mask_loss: 0.2624 - val_loss: 1.2385 - val_rpn_class_loss: 0.0765 - val_rpn_bbox_loss: 0.3578 - val_mrcnn_class_loss: 0.3785 - val_mrcnn_bbox_loss: 0.1353 - val_mrcnn_mask_loss: 0.2904\n",
      "Epoch 120/125\n",
      "10/10 [==============================] - 47s 5s/step - loss: 0.9634 - rpn_class_loss: 0.0197 - rpn_bbox_loss: 0.2684 - mrcnn_class_loss: 0.2786 - mrcnn_bbox_loss: 0.1358 - mrcnn_mask_loss: 0.2608 - val_loss: 1.0773 - val_rpn_class_loss: 0.0505 - val_rpn_bbox_loss: 0.3058 - val_mrcnn_class_loss: 0.3301 - val_mrcnn_bbox_loss: 0.1305 - val_mrcnn_mask_loss: 0.2604\n",
      "Epoch 121/125\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.9443 - rpn_class_loss: 0.0155 - rpn_bbox_loss: 0.2609 - mrcnn_class_loss: 0.2733 - mrcnn_bbox_loss: 0.1351 - mrcnn_mask_loss: 0.2595 - val_loss: 1.0165 - val_rpn_class_loss: 0.0440 - val_rpn_bbox_loss: 0.2922 - val_mrcnn_class_loss: 0.3096 - val_mrcnn_bbox_loss: 0.1224 - val_mrcnn_mask_loss: 0.2482\n",
      "Epoch 122/125\n",
      "10/10 [==============================] - 49s 5s/step - loss: 0.9195 - rpn_class_loss: 0.0184 - rpn_bbox_loss: 0.2734 - mrcnn_class_loss: 0.2391 - mrcnn_bbox_loss: 0.1324 - mrcnn_mask_loss: 0.2562 - val_loss: 1.0053 - val_rpn_class_loss: 0.0442 - val_rpn_bbox_loss: 0.2919 - val_mrcnn_class_loss: 0.3053 - val_mrcnn_bbox_loss: 0.1186 - val_mrcnn_mask_loss: 0.2453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/125\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.9297 - rpn_class_loss: 0.0229 - rpn_bbox_loss: 0.2946 - mrcnn_class_loss: 0.2204 - mrcnn_bbox_loss: 0.1331 - mrcnn_mask_loss: 0.2587 - val_loss: 1.0369 - val_rpn_class_loss: 0.0441 - val_rpn_bbox_loss: 0.2916 - val_mrcnn_class_loss: 0.3185 - val_mrcnn_bbox_loss: 0.1277 - val_mrcnn_mask_loss: 0.2550\n",
      "Epoch 124/125\n",
      "10/10 [==============================] - 39s 4s/step - loss: 0.9063 - rpn_class_loss: 0.0212 - rpn_bbox_loss: 0.2886 - mrcnn_class_loss: 0.2093 - mrcnn_bbox_loss: 0.1310 - mrcnn_mask_loss: 0.2563 - val_loss: 1.0271 - val_rpn_class_loss: 0.0442 - val_rpn_bbox_loss: 0.2914 - val_mrcnn_class_loss: 0.3183 - val_mrcnn_bbox_loss: 0.1235 - val_mrcnn_mask_loss: 0.2496\n",
      "Epoch 125/125\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.8018 - rpn_class_loss: 0.0189 - rpn_bbox_loss: 0.2393 - mrcnn_class_loss: 0.1840 - mrcnn_bbox_loss: 0.1150 - mrcnn_mask_loss: 0.2447 - val_loss: 1.1352 - val_rpn_class_loss: 0.0743 - val_rpn_bbox_loss: 0.3206 - val_mrcnn_class_loss: 0.3325 - val_mrcnn_bbox_loss: 0.1378 - val_mrcnn_mask_loss: 0.2701\n"
     ]
    }
   ],
   "source": [
    "#e395-e409(with 0.9 min_detection); lr*1, lm=0.7 - 73.7% (70.19%)\n",
    "#e410-e419-429; lr*1, lm=0.8 - 74.78%-74.45%\n",
    "#e430-e449-459(with 0.9 min_detection)-464; lr*5, lm=0.8 - 75.34%-75.13%(73.97%)-(73.89%)\n",
    "#e465-e479 (with 0.9 min_detection henceforth); lr*10, lm=0.8 -- 73.87%\n",
    "#e480-e489 (with 0.9 min_detection henceforth); lr*5, lm=0.9 -- 74.18% (e481)\n",
    "#e481-e489-e499; lr*3, lm=0.9--74.23% (e485)\n",
    "#e500-509-519-529; lr*5,8,8 lm=0.9--74.16 (e502),74.20% (e518), 73.99% (e528)\n",
    "#e530-569; lr*10,lm=0.9--74.23% (e530) 74.69% (e566)\n",
    "#Changing val to val_rev_1 henceforth (big axon label flipped); steps_per_epoch=9; validation_steps = 4\n",
    "#e567-602; lr*10,lm=0.9--74.86(e589)\n",
    "#e590-629; lr*10, lm=0.9 -- 75.13 (e607)\n",
    "#USE_MINI_MASK=False\n",
    "#e608-629: lr*20; lm=0.9\n",
    "print(\"Fine tune all layers\")\n",
    "config.LEARNING_MOMENTUM = 0.7\n",
    "config.LEARNING_RATE = 0.0001\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=125,\n",
    "            layers='all'#,\n",
    "            #custom_callbacks=[mean_f1_callback]\n",
    "           )\n",
    "            #augmentation=augmentation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
