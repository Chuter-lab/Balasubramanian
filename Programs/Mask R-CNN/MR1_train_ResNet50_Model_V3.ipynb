{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e67ee4a7",
   "metadata": {},
   "source": [
    "\n",
    "#### Author: Madhusudhanan Balasubramanian (MB), Ph.D., The University of Memphis\n",
    "#### V3: Feb 04, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab36144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        400\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                15\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               400\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    3\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        8000\n",
      "POST_NMS_ROIS_TRAINING         1800\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    400\n",
      "STEPS_PER_EPOCH                75\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           400\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               15\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading weights from /home/madhu/Lab/Members/00_madhu/Programs/axon_segmentation/logs/coco20220224T1918//mask_rcnn_coco_0022.h5\n"
     ]
    }
   ],
   "source": [
    "#Dec 10, 2021: based on train_axon_annotation_model.ipynb\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "import imgaug\n",
    "\n",
    "# Root directory of the project\n",
    "#ROOT_DIR = os.path.abspath(\"../../\")\n",
    "ROOT_DIR = \"./Mask_RCNN\";\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "#Model configuration for training\n",
    "#---------------------------------\n",
    "import axon_coco as coco #copied samples/coco/coco.py as axon_coco.py\n",
    "config = coco.CocoConfig()\n",
    "#Dec 09, 2021 MB notes: Initially, no other configuration changes needed for training (recall / see that\n",
    "# configuration changes required for inferences such as setting # GPUs to 1, etc. See axon_coco.py for \n",
    "# other possible configuration changes\n",
    "config.BACKBONE = 'resnet50' #default is resnet101\n",
    "config.IMAGES_PER_GPU = 1\n",
    "config.GPU_COUNT = 1\n",
    "config.BATCH_SIZE = config.IMAGES_PER_GPU * config.GPU_COUNT #BATCH_SIZE calculated only in config.py's constructor in line 216\n",
    "config.STEPS_PER_EPOCH = 75 #Jan 07: reduced from 100 to 75\n",
    "#MB, Jan 07, 2022:\n",
    "config.VALIDATION_STEPS = 15 #originally 5, previously set at 15\n",
    "#References for increasing number of detections: https://github.com/matterport/Mask_RCNN/issues/1884#:~:text=What%20seems%20to%20have%20had%20the%20greatest%20impact%20for%20us%20were%20the%20training%20configs%3A\n",
    "#\n",
    "config.RPN_TRAIN_ANCHORS_PER_IMAGE = 400 #default is 256\n",
    "config.MAX_GT_INSTANCES = 400\n",
    "config.PRE_NMS_LIMIT = 6000\n",
    "config.POST_NMS_ROIS_TRAINING = 1800 #ROIs kept after non-maximum supression; default is 2000\n",
    "#\n",
    "config.TRAIN_ROIS_PER_IMAGE = 400 #default is 200; setting (450) slightly higher than MAX_GT_INSTANCES (300)\n",
    "#MB: need to add the following to the inference module\n",
    "#-----------------------------------------------------\n",
    "config.DETECTION_MAX_INSTANCES = 400\n",
    "config.POST_NMS_ROIS_INFERENCE = 8000\n",
    "#MB: https://medium.com/@umdfirecoml/training-a-mask-r-cnn-model-using-the-nucleus-data-bcb5fdbc0181 \n",
    "config.DETECTION_MIN_CONFIDENCE = 0.7\n",
    "config.RPN_NMS_THRESHOLD = 0.7 #default is 0.7; higher values increases the number of region proposals\n",
    "#config.MAX_GT_INSTANCES = 250 #default 100\n",
    "#\n",
    "config.display()\n",
    "\n",
    "#Data\n",
    "#-----\n",
    "COCO_DIR = \"./DataFiles/\"\n",
    "#\n",
    "#Axon training data\n",
    "dataset_train = coco.CocoDataset()\n",
    "dataset_train.load_coco(COCO_DIR, \"dataset_train\")\n",
    "dataset_train.prepare() # Must call before using the dataset\n",
    "#\n",
    "#Axon annotation validation data\n",
    "dataset_val = coco.CocoDataset()\n",
    "dataset_val.load_coco(COCO_DIR, \"dataset_val\")\n",
    "dataset_val.prepare() # Must call before using the dataset\n",
    "\n",
    "# Create a model in the \"training\" mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir = coco.DEFAULT_LOGS_DIR)\n",
    "\n",
    "# Set starting network weights\n",
    "# MB Dec 10, 2021: Current training schedule: initially start with \"coco\"; later switch to \"specific\" and \"last\"\n",
    "init_with = \"specific\"\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    #MB, Jan 11, 2022\n",
    "    # Download COCO trained weights from Releases if needed -- MB - this needs to be checked if it can download\n",
    "    #if not os.path.exists(coco.COCO_MODEL_PATH):\n",
    "    #    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "    \n",
    "    #model.load_weights(coco.COCO_MODEL_PATH, by_name = True,\n",
    "    model_path = os.path.join(coco.ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "    model.load_weights(model_path, by_name = True,\n",
    "                      exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                              \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"specific\":\n",
    "    #MB Dec 09, 2021: \"specific\" was added to resume training the axon model (not from an initial COCO model)\n",
    "    # So, no need to exclude certain layers as above for \"coco\".  You would choose \"coco\" to start from scratch\n",
    "    #\n",
    "    # Get path to saved weights\n",
    "    #model_path = os.path.join(coco.ROOT_DIR, \"on_axon_mrcnn_r50_Ex.h5\")\n",
    "    model_path = os.path.join(coco.ROOT_DIR, \"logs/coco20220224T1918//mask_rcnn_coco_0022.h5\")\n",
    "\n",
    "    #Load the trained weights\n",
    "    assert model_path != \"\", \"Provide path to the trained weights\"\n",
    "    print(\"Loading weights from\", model_path)\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "elif init_with == \"last\":\n",
    "    #Load the last model training to resume training\n",
    "    model.load_weights(model.find_last(), by_name=True)\n",
    "    \n",
    "# Image Augmentation\n",
    "# Right/Left flip 50% of the time\n",
    "# augmentation = imgaug.augmenters.Fliplr(0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f02c867",
   "metadata": {},
   "source": [
    "## Train heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785f158f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/madhu/Lab/Members/00_madhu/Programs/axon_segmentation/logs/coco20220207T1734/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/20\n",
      "75/75 [==============================] - 2103s 28s/step - loss: 2.6079 - rpn_class_loss: 0.4652 - rpn_bbox_loss: 0.4733 - mrcnn_class_loss: 0.6779 - mrcnn_bbox_loss: 0.3727 - mrcnn_mask_loss: 0.6188 - val_loss: 1.6543 - val_rpn_class_loss: 0.1821 - val_rpn_bbox_loss: 0.2970 - val_mrcnn_class_loss: 0.6150 - val_mrcnn_bbox_loss: 0.2435 - val_mrcnn_mask_loss: 0.3166\n",
      "Epoch 2/20\n",
      "75/75 [==============================] - 1921s 26s/step - loss: 1.4371 - rpn_class_loss: 0.1683 - rpn_bbox_loss: 0.2928 - mrcnn_class_loss: 0.4979 - mrcnn_bbox_loss: 0.1943 - mrcnn_mask_loss: 0.2838 - val_loss: 1.4920 - val_rpn_class_loss: 0.1414 - val_rpn_bbox_loss: 0.2428 - val_mrcnn_class_loss: 0.6175 - val_mrcnn_bbox_loss: 0.2206 - val_mrcnn_mask_loss: 0.2697\n",
      "Epoch 3/20\n",
      "75/75 [==============================] - 1930s 26s/step - loss: 1.5932 - rpn_class_loss: 0.1656 - rpn_bbox_loss: 0.2826 - mrcnn_class_loss: 0.5754 - mrcnn_bbox_loss: 0.2539 - mrcnn_mask_loss: 0.3156 - val_loss: 1.4272 - val_rpn_class_loss: 0.1261 - val_rpn_bbox_loss: 0.1978 - val_mrcnn_class_loss: 0.6162 - val_mrcnn_bbox_loss: 0.2193 - val_mrcnn_mask_loss: 0.2677\n",
      "Epoch 4/20\n",
      "75/75 [==============================] - 1922s 26s/step - loss: 1.4374 - rpn_class_loss: 0.1809 - rpn_bbox_loss: 0.2854 - mrcnn_class_loss: 0.4871 - mrcnn_bbox_loss: 0.1994 - mrcnn_mask_loss: 0.2845 - val_loss: 2.0584 - val_rpn_class_loss: 0.4099 - val_rpn_bbox_loss: 0.3273 - val_mrcnn_class_loss: 0.7422 - val_mrcnn_bbox_loss: 0.3160 - val_mrcnn_mask_loss: 0.2630\n",
      "Epoch 5/20\n",
      "75/75 [==============================] - 1930s 26s/step - loss: 1.3110 - rpn_class_loss: 0.1280 - rpn_bbox_loss: 0.2527 - mrcnn_class_loss: 0.4862 - mrcnn_bbox_loss: 0.1723 - mrcnn_mask_loss: 0.2718 - val_loss: 1.9147 - val_rpn_class_loss: 0.3532 - val_rpn_bbox_loss: 0.2775 - val_mrcnn_class_loss: 0.7836 - val_mrcnn_bbox_loss: 0.2433 - val_mrcnn_mask_loss: 0.2571\n",
      "Epoch 6/20\n",
      "75/75 [==============================] - 1935s 26s/step - loss: 1.4230 - rpn_class_loss: 0.1387 - rpn_bbox_loss: 0.3014 - mrcnn_class_loss: 0.4874 - mrcnn_bbox_loss: 0.2074 - mrcnn_mask_loss: 0.2882 - val_loss: 1.4403 - val_rpn_class_loss: 0.1649 - val_rpn_bbox_loss: 0.1931 - val_mrcnn_class_loss: 0.6152 - val_mrcnn_bbox_loss: 0.2056 - val_mrcnn_mask_loss: 0.2615\n",
      "Epoch 7/20\n",
      "75/75 [==============================] - 1922s 26s/step - loss: 1.1036 - rpn_class_loss: 0.0942 - rpn_bbox_loss: 0.1899 - mrcnn_class_loss: 0.4094 - mrcnn_bbox_loss: 0.1496 - mrcnn_mask_loss: 0.2605 - val_loss: 1.4248 - val_rpn_class_loss: 0.1277 - val_rpn_bbox_loss: 0.1738 - val_mrcnn_class_loss: 0.6499 - val_mrcnn_bbox_loss: 0.2117 - val_mrcnn_mask_loss: 0.2616\n",
      "Epoch 8/20\n",
      "75/75 [==============================] - 1916s 26s/step - loss: 1.3979 - rpn_class_loss: 0.1284 - rpn_bbox_loss: 0.2524 - mrcnn_class_loss: 0.5086 - mrcnn_bbox_loss: 0.2120 - mrcnn_mask_loss: 0.2965 - val_loss: 1.9657 - val_rpn_class_loss: 0.2077 - val_rpn_bbox_loss: 0.1817 - val_mrcnn_class_loss: 1.0283 - val_mrcnn_bbox_loss: 0.2727 - val_mrcnn_mask_loss: 0.2754\n",
      "Epoch 9/20\n",
      "75/75 [==============================] - 1930s 26s/step - loss: 1.2451 - rpn_class_loss: 0.1341 - rpn_bbox_loss: 0.1931 - mrcnn_class_loss: 0.4531 - mrcnn_bbox_loss: 0.1783 - mrcnn_mask_loss: 0.2865 - val_loss: 2.3136 - val_rpn_class_loss: 0.2096 - val_rpn_bbox_loss: 0.3279 - val_mrcnn_class_loss: 1.2719 - val_mrcnn_bbox_loss: 0.2298 - val_mrcnn_mask_loss: 0.2744\n",
      "Epoch 10/20\n",
      "75/75 [==============================] - 1934s 26s/step - loss: 1.2487 - rpn_class_loss: 0.1251 - rpn_bbox_loss: 0.2287 - mrcnn_class_loss: 0.4514 - mrcnn_bbox_loss: 0.1689 - mrcnn_mask_loss: 0.2746 - val_loss: 1.3788 - val_rpn_class_loss: 0.1727 - val_rpn_bbox_loss: 0.2380 - val_mrcnn_class_loss: 0.4960 - val_mrcnn_bbox_loss: 0.2112 - val_mrcnn_mask_loss: 0.2608\n",
      "Epoch 11/20\n",
      "75/75 [==============================] - 1918s 26s/step - loss: 1.1090 - rpn_class_loss: 0.1203 - rpn_bbox_loss: 0.2179 - mrcnn_class_loss: 0.3620 - mrcnn_bbox_loss: 0.1447 - mrcnn_mask_loss: 0.2642 - val_loss: 1.3398 - val_rpn_class_loss: 0.0880 - val_rpn_bbox_loss: 0.1782 - val_mrcnn_class_loss: 0.5829 - val_mrcnn_bbox_loss: 0.2259 - val_mrcnn_mask_loss: 0.2648\n",
      "Epoch 12/20\n",
      "75/75 [==============================] - 1921s 26s/step - loss: 1.0765 - rpn_class_loss: 0.0960 - rpn_bbox_loss: 0.1742 - mrcnn_class_loss: 0.4098 - mrcnn_bbox_loss: 0.1423 - mrcnn_mask_loss: 0.2541 - val_loss: 1.8598 - val_rpn_class_loss: 0.2406 - val_rpn_bbox_loss: 0.2900 - val_mrcnn_class_loss: 0.7965 - val_mrcnn_bbox_loss: 0.2785 - val_mrcnn_mask_loss: 0.2542\n",
      "Epoch 13/20\n",
      "75/75 [==============================] - 1927s 26s/step - loss: 1.0824 - rpn_class_loss: 0.0947 - rpn_bbox_loss: 0.2415 - mrcnn_class_loss: 0.3567 - mrcnn_bbox_loss: 0.1383 - mrcnn_mask_loss: 0.2512 - val_loss: 2.0343 - val_rpn_class_loss: 0.2309 - val_rpn_bbox_loss: 0.3109 - val_mrcnn_class_loss: 1.0035 - val_mrcnn_bbox_loss: 0.2268 - val_mrcnn_mask_loss: 0.2622\n",
      "Epoch 14/20\n",
      "75/75 [==============================] - 1918s 26s/step - loss: 1.2545 - rpn_class_loss: 0.1276 - rpn_bbox_loss: 0.2173 - mrcnn_class_loss: 0.4768 - mrcnn_bbox_loss: 0.1619 - mrcnn_mask_loss: 0.2708 - val_loss: 1.3664 - val_rpn_class_loss: 0.1228 - val_rpn_bbox_loss: 0.2080 - val_mrcnn_class_loss: 0.5723 - val_mrcnn_bbox_loss: 0.2078 - val_mrcnn_mask_loss: 0.2555\n",
      "Epoch 15/20\n",
      "75/75 [==============================] - 1927s 26s/step - loss: 1.1281 - rpn_class_loss: 0.1085 - rpn_bbox_loss: 0.2215 - mrcnn_class_loss: 0.3774 - mrcnn_bbox_loss: 0.1521 - mrcnn_mask_loss: 0.2686 - val_loss: 2.0685 - val_rpn_class_loss: 0.1620 - val_rpn_bbox_loss: 0.2397 - val_mrcnn_class_loss: 1.1950 - val_mrcnn_bbox_loss: 0.2201 - val_mrcnn_mask_loss: 0.2517\n",
      "Epoch 16/20\n",
      "75/75 [==============================] - 1930s 26s/step - loss: 1.0420 - rpn_class_loss: 0.0922 - rpn_bbox_loss: 0.1790 - mrcnn_class_loss: 0.3636 - mrcnn_bbox_loss: 0.1435 - mrcnn_mask_loss: 0.2638 - val_loss: 1.3013 - val_rpn_class_loss: 0.0665 - val_rpn_bbox_loss: 0.1906 - val_mrcnn_class_loss: 0.5795 - val_mrcnn_bbox_loss: 0.2162 - val_mrcnn_mask_loss: 0.2485\n",
      "Epoch 17/20\n",
      "75/75 [==============================] - 1918s 26s/step - loss: 0.9932 - rpn_class_loss: 0.1055 - rpn_bbox_loss: 0.1802 - mrcnn_class_loss: 0.3458 - mrcnn_bbox_loss: 0.1186 - mrcnn_mask_loss: 0.2431 - val_loss: 1.3376 - val_rpn_class_loss: 0.1551 - val_rpn_bbox_loss: 0.1889 - val_mrcnn_class_loss: 0.5433 - val_mrcnn_bbox_loss: 0.1960 - val_mrcnn_mask_loss: 0.2543\n",
      "Epoch 18/20\n",
      "75/75 [==============================] - 1918s 26s/step - loss: 0.9804 - rpn_class_loss: 0.0979 - rpn_bbox_loss: 0.1668 - mrcnn_class_loss: 0.3343 - mrcnn_bbox_loss: 0.1154 - mrcnn_mask_loss: 0.2659 - val_loss: 1.8814 - val_rpn_class_loss: 0.1946 - val_rpn_bbox_loss: 0.2134 - val_mrcnn_class_loss: 0.9839 - val_mrcnn_bbox_loss: 0.2219 - val_mrcnn_mask_loss: 0.2676\n",
      "Epoch 19/20\n",
      "75/75 [==============================] - 1923s 26s/step - loss: 1.0150 - rpn_class_loss: 0.0880 - rpn_bbox_loss: 0.1862 - mrcnn_class_loss: 0.3477 - mrcnn_bbox_loss: 0.1304 - mrcnn_mask_loss: 0.2627 - val_loss: 2.0228 - val_rpn_class_loss: 0.1272 - val_rpn_bbox_loss: 0.2422 - val_mrcnn_class_loss: 1.1736 - val_mrcnn_bbox_loss: 0.2210 - val_mrcnn_mask_loss: 0.2588\n",
      "Epoch 20/20\n",
      "75/75 [==============================] - 1926s 26s/step - loss: 0.9824 - rpn_class_loss: 0.0729 - rpn_bbox_loss: 0.1845 - mrcnn_class_loss: 0.3360 - mrcnn_bbox_loss: 0.1257 - mrcnn_mask_loss: 0.2633 - val_loss: 1.3910 - val_rpn_class_loss: 0.1409 - val_rpn_bbox_loss: 0.2249 - val_mrcnn_class_loss: 0.5354 - val_mrcnn_bbox_loss: 0.2221 - val_mrcnn_mask_loss: 0.2675\n",
      "Heads training for 20 epochs took 645.37 minutes\n"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "start_train = time.time()\n",
    "heads_training_epochs = 20\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=heads_training_epochs, \n",
    "            layers='heads')\n",
    "            #augmentation=augmentation) # unfreeze head and just train on last layer\n",
    "end_train = time.time()\n",
    "minutes = round((end_train - start_train) / 60, 2)\n",
    "print(f'Heads training for {heads_training_epochs} epochs took {minutes} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a8adb",
   "metadata": {},
   "source": [
    "## Fine tune ResNet Stage 4 and up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50910586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tune Resnet stage 4 and up\n",
      "\n",
      "Starting at epoch 20. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/madhu/Lab/Members/00_madhu/Programs/axon_segmentation/logs/coco20220207T1734/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 21/40\n",
      "75/75 [==============================] - 2826s 38s/step - loss: 0.9830 - rpn_class_loss: 0.0776 - rpn_bbox_loss: 0.1788 - mrcnn_class_loss: 0.3371 - mrcnn_bbox_loss: 0.1283 - mrcnn_mask_loss: 0.2612 - val_loss: 1.4689 - val_rpn_class_loss: 0.1599 - val_rpn_bbox_loss: 0.2389 - val_mrcnn_class_loss: 0.5806 - val_mrcnn_bbox_loss: 0.2294 - val_mrcnn_mask_loss: 0.2602\n",
      "Epoch 22/40\n",
      "75/75 [==============================] - 2649s 35s/step - loss: 0.8042 - rpn_class_loss: 0.0471 - rpn_bbox_loss: 0.1596 - mrcnn_class_loss: 0.2454 - mrcnn_bbox_loss: 0.1033 - mrcnn_mask_loss: 0.2488 - val_loss: 1.6209 - val_rpn_class_loss: 0.1207 - val_rpn_bbox_loss: 0.2425 - val_mrcnn_class_loss: 0.7751 - val_mrcnn_bbox_loss: 0.2243 - val_mrcnn_mask_loss: 0.2583\n",
      "Epoch 23/40\n",
      "75/75 [==============================] - 2677s 36s/step - loss: 0.9432 - rpn_class_loss: 0.0646 - rpn_bbox_loss: 0.1564 - mrcnn_class_loss: 0.3238 - mrcnn_bbox_loss: 0.1264 - mrcnn_mask_loss: 0.2721 - val_loss: 1.2202 - val_rpn_class_loss: 0.0772 - val_rpn_bbox_loss: 0.1708 - val_mrcnn_class_loss: 0.5282 - val_mrcnn_bbox_loss: 0.1967 - val_mrcnn_mask_loss: 0.2474\n",
      "Epoch 24/40\n",
      "75/75 [==============================] - 2642s 35s/step - loss: 0.9428 - rpn_class_loss: 0.0675 - rpn_bbox_loss: 0.1732 - mrcnn_class_loss: 0.3131 - mrcnn_bbox_loss: 0.1255 - mrcnn_mask_loss: 0.2635 - val_loss: 1.7558 - val_rpn_class_loss: 0.1879 - val_rpn_bbox_loss: 0.3292 - val_mrcnn_class_loss: 0.7752 - val_mrcnn_bbox_loss: 0.2161 - val_mrcnn_mask_loss: 0.2474\n",
      "Epoch 25/40\n",
      "75/75 [==============================] - 2654s 35s/step - loss: 0.7394 - rpn_class_loss: 0.0301 - rpn_bbox_loss: 0.1370 - mrcnn_class_loss: 0.2293 - mrcnn_bbox_loss: 0.0948 - mrcnn_mask_loss: 0.2481 - val_loss: 1.7492 - val_rpn_class_loss: 0.1686 - val_rpn_bbox_loss: 0.2638 - val_mrcnn_class_loss: 0.8393 - val_mrcnn_bbox_loss: 0.2237 - val_mrcnn_mask_loss: 0.2538\n",
      "Epoch 26/40\n",
      "75/75 [==============================] - 2674s 36s/step - loss: 0.7809 - rpn_class_loss: 0.0408 - rpn_bbox_loss: 0.1619 - mrcnn_class_loss: 0.2272 - mrcnn_bbox_loss: 0.0978 - mrcnn_mask_loss: 0.2532 - val_loss: 1.6246 - val_rpn_class_loss: 0.1235 - val_rpn_bbox_loss: 0.1970 - val_mrcnn_class_loss: 0.8182 - val_mrcnn_bbox_loss: 0.2227 - val_mrcnn_mask_loss: 0.2633\n",
      "Epoch 27/40\n",
      "75/75 [==============================] - 2655s 35s/step - loss: 0.6174 - rpn_class_loss: 0.0236 - rpn_bbox_loss: 0.1084 - mrcnn_class_loss: 0.1754 - mrcnn_bbox_loss: 0.0747 - mrcnn_mask_loss: 0.2354 - val_loss: 1.6384 - val_rpn_class_loss: 0.0916 - val_rpn_bbox_loss: 0.1879 - val_mrcnn_class_loss: 0.8851 - val_mrcnn_bbox_loss: 0.2099 - val_mrcnn_mask_loss: 0.2639\n",
      "Epoch 28/40\n",
      "75/75 [==============================] - 2657s 35s/step - loss: 0.8182 - rpn_class_loss: 0.0411 - rpn_bbox_loss: 0.1407 - mrcnn_class_loss: 0.2521 - mrcnn_bbox_loss: 0.1136 - mrcnn_mask_loss: 0.2708 - val_loss: 2.1533 - val_rpn_class_loss: 0.1289 - val_rpn_bbox_loss: 0.2009 - val_mrcnn_class_loss: 1.3514 - val_mrcnn_bbox_loss: 0.2040 - val_mrcnn_mask_loss: 0.2681\n",
      "Epoch 29/40\n",
      "75/75 [==============================] - 2674s 36s/step - loss: 0.6506 - rpn_class_loss: 0.0315 - rpn_bbox_loss: 0.0886 - mrcnn_class_loss: 0.2007 - mrcnn_bbox_loss: 0.0775 - mrcnn_mask_loss: 0.2523 - val_loss: 2.3852 - val_rpn_class_loss: 0.2626 - val_rpn_bbox_loss: 0.2977 - val_mrcnn_class_loss: 1.3274 - val_mrcnn_bbox_loss: 0.2194 - val_mrcnn_mask_loss: 0.2781\n",
      "Epoch 30/40\n",
      "75/75 [==============================] - 2670s 36s/step - loss: 0.6724 - rpn_class_loss: 0.0328 - rpn_bbox_loss: 0.1196 - mrcnn_class_loss: 0.1893 - mrcnn_bbox_loss: 0.0849 - mrcnn_mask_loss: 0.2457 - val_loss: 1.5341 - val_rpn_class_loss: 0.2075 - val_rpn_bbox_loss: 0.2573 - val_mrcnn_class_loss: 0.6076 - val_mrcnn_bbox_loss: 0.2078 - val_mrcnn_mask_loss: 0.2539\n",
      "Epoch 31/40\n",
      "75/75 [==============================] - 2653s 35s/step - loss: 0.6510 - rpn_class_loss: 0.0338 - rpn_bbox_loss: 0.1247 - mrcnn_class_loss: 0.1716 - mrcnn_bbox_loss: 0.0827 - mrcnn_mask_loss: 0.2383 - val_loss: 1.4815 - val_rpn_class_loss: 0.0561 - val_rpn_bbox_loss: 0.1944 - val_mrcnn_class_loss: 0.7667 - val_mrcnn_bbox_loss: 0.1967 - val_mrcnn_mask_loss: 0.2675\n",
      "Epoch 32/40\n",
      "75/75 [==============================] - 2377s 32s/step - loss: 0.5480 - rpn_class_loss: 0.0168 - rpn_bbox_loss: 0.0874 - mrcnn_class_loss: 0.1476 - mrcnn_bbox_loss: 0.0687 - mrcnn_mask_loss: 0.2276 - val_loss: 1.9811 - val_rpn_class_loss: 0.1421 - val_rpn_bbox_loss: 0.2654 - val_mrcnn_class_loss: 1.0759 - val_mrcnn_bbox_loss: 0.2344 - val_mrcnn_mask_loss: 0.2634\n",
      "Epoch 33/40\n",
      "75/75 [==============================] - 1987s 26s/step - loss: 0.5530 - rpn_class_loss: 0.0150 - rpn_bbox_loss: 0.1049 - mrcnn_class_loss: 0.1432 - mrcnn_bbox_loss: 0.0647 - mrcnn_mask_loss: 0.2252 - val_loss: 2.0919 - val_rpn_class_loss: 0.1357 - val_rpn_bbox_loss: 0.2439 - val_mrcnn_class_loss: 1.1901 - val_mrcnn_bbox_loss: 0.2210 - val_mrcnn_mask_loss: 0.3013\n",
      "Epoch 34/40\n",
      "75/75 [==============================] - 1980s 26s/step - loss: 0.5930 - rpn_class_loss: 0.0277 - rpn_bbox_loss: 0.0963 - mrcnn_class_loss: 0.1594 - mrcnn_bbox_loss: 0.0722 - mrcnn_mask_loss: 0.2374 - val_loss: 1.9303 - val_rpn_class_loss: 0.1639 - val_rpn_bbox_loss: 0.2454 - val_mrcnn_class_loss: 1.0335 - val_mrcnn_bbox_loss: 0.2113 - val_mrcnn_mask_loss: 0.2763\n",
      "Epoch 35/40\n",
      "75/75 [==============================] - 1984s 26s/step - loss: 0.5506 - rpn_class_loss: 0.0191 - rpn_bbox_loss: 0.0988 - mrcnn_class_loss: 0.1353 - mrcnn_bbox_loss: 0.0642 - mrcnn_mask_loss: 0.2332 - val_loss: 2.3363 - val_rpn_class_loss: 0.0961 - val_rpn_bbox_loss: 0.2165 - val_mrcnn_class_loss: 1.5219 - val_mrcnn_bbox_loss: 0.2255 - val_mrcnn_mask_loss: 0.2764\n",
      "Epoch 36/40\n",
      "75/75 [==============================] - 1988s 27s/step - loss: 0.5113 - rpn_class_loss: 0.0133 - rpn_bbox_loss: 0.0745 - mrcnn_class_loss: 0.1282 - mrcnn_bbox_loss: 0.0604 - mrcnn_mask_loss: 0.2348 - val_loss: 1.6946 - val_rpn_class_loss: 0.0703 - val_rpn_bbox_loss: 0.2008 - val_mrcnn_class_loss: 0.9518 - val_mrcnn_bbox_loss: 0.2001 - val_mrcnn_mask_loss: 0.2715\n",
      "Epoch 37/40\n",
      "75/75 [==============================] - 1972s 26s/step - loss: 0.5184 - rpn_class_loss: 0.0198 - rpn_bbox_loss: 0.0982 - mrcnn_class_loss: 0.1171 - mrcnn_bbox_loss: 0.0579 - mrcnn_mask_loss: 0.2255 - val_loss: 1.9483 - val_rpn_class_loss: 0.1810 - val_rpn_bbox_loss: 0.1984 - val_mrcnn_class_loss: 1.0752 - val_mrcnn_bbox_loss: 0.2187 - val_mrcnn_mask_loss: 0.2750\n",
      "Epoch 38/40\n",
      "75/75 [==============================] - 1973s 26s/step - loss: 0.4731 - rpn_class_loss: 0.0124 - rpn_bbox_loss: 0.0696 - mrcnn_class_loss: 0.1206 - mrcnn_bbox_loss: 0.0491 - mrcnn_mask_loss: 0.2214 - val_loss: 2.0216 - val_rpn_class_loss: 0.1309 - val_rpn_bbox_loss: 0.1952 - val_mrcnn_class_loss: 1.1762 - val_mrcnn_bbox_loss: 0.2178 - val_mrcnn_mask_loss: 0.3014\n",
      "Epoch 39/40\n",
      "75/75 [==============================] - 1977s 26s/step - loss: 0.4661 - rpn_class_loss: 0.0143 - rpn_bbox_loss: 0.0676 - mrcnn_class_loss: 0.1162 - mrcnn_bbox_loss: 0.0520 - mrcnn_mask_loss: 0.2159 - val_loss: 1.8829 - val_rpn_class_loss: 0.0764 - val_rpn_bbox_loss: 0.2382 - val_mrcnn_class_loss: 1.0775 - val_mrcnn_bbox_loss: 0.2131 - val_mrcnn_mask_loss: 0.2777\n",
      "Epoch 40/40\n",
      "75/75 [==============================] - 1981s 26s/step - loss: 0.4320 - rpn_class_loss: 0.0135 - rpn_bbox_loss: 0.0675 - mrcnn_class_loss: 0.0998 - mrcnn_bbox_loss: 0.0431 - mrcnn_mask_loss: 0.2081 - val_loss: 1.7852 - val_rpn_class_loss: 0.1639 - val_rpn_bbox_loss: 0.2207 - val_mrcnn_class_loss: 0.8913 - val_mrcnn_bbox_loss: 0.2149 - val_mrcnn_mask_loss: 0.2944\n"
     ]
    }
   ],
   "source": [
    "# Training - Stage 2\n",
    "# Finetune layers from ResNet stage 4 and up\n",
    "print(\"Fine tune Resnet stage 4 and up\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=40,\n",
    "            layers='4+')\n",
    "            #augmentation=augmentation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
